\chapter{Introdução}
\label{ch:introducao}

Florestas tropicais proveem moradia para a maioria das espécies de animais e plantas terrestres do mundo. Estes ecossistemas estão sob crescente ameaça em todo o mundo. Estimativas recentes indicam que durante a década passada 5,8 $ \pm $ 1,4 milhões de hectares de floresta tropical úmida foram perdidos a cada ano, com mais 2,3 $ \pm $ 0,7 milhões de hectares de florestas parcialmente degradados \cite{Achard2002}. Em todas as regiões tropicais úmidas, o desflorestamento é em geral resultado da extração e comercialização de madeira, da agropecuária e da expansão da infraestrutura de transporte terrestre \cite{Hassan2005,Nepstad2002}. Com inúmeras áreas de concessões se esgotando rapidamente, a extração ilegal de madeira está se tornando um fator importante no mercado de madeira, particularmente em regiões e países com governança deficiente \cite{Hassan2005,Curran2004, Asner2005}. Seus efeitos negativos incluem o empobrecimento da paisagem florestal, com impactos em comunidades locais e o fortalecimento da corrupção e organizações criminosas \cite{Hassan2005}. 

No passado, unidades de conservação, como reservas indígenas, reservas ecológicas e florestas nacionais, proporcionavam proteção contra a extração ilegal de madeira. Atualmente, essa situação não é mais verdadeira e unidades de conservação estão sob crescente ameaça, por exemplo na Indonésia \cite{Curran2004}, no Brasil \cite{Asner2005,Schwartzman2000} e provavelmente em outros lugares.

Informações sobre as florestas do mundo são limitadas e desigualmente distribuídas. O \textit{Global Forest Resources Assessment} (FRA) 2000 \cite{Fao2001}, preparado pela \textit{Food and Agriculture Organization} (FAO) das Nações Unidas, relata que apenas 22 dos 137 países em desenvolvimento realizavam inventários periódicos. A situação pouco melhorou desde então. Muitos países possuem apenas inventários florestais anteriores a 1990 e poucos têm programas de monitoramento regulares \cite{Hassan2005}. Exceções existem como o Projeto de Monitoramento do Desmatamento na Amazônia Legal (PRODES) e o Sistema de Detecção do Desmatamento em Tempo Real (DETER), desenvolvidos pelo INPE. 

O INPE utiliza imagens dos satélites TERRA e ACQUA para fornecer alertas semanais para áreas acima de 25 hectares desmatadas na Amazônia brasileira. Contudo, apesar da acessibilidade das novas tecnologias e sistemas de sensoriamento remoto, resultados  continuam longe do ótimo devido ao crescimento populacional, governança pobre e, sobretudo, ao aumento mundial do consumo de produtos florestais e agropecuários. Claramente, a imensa tarefa de proteger para gerações futuras uma parte adequada das florestas remanescentes do mundo está talvez fora do alcance de estratégias de conservação tradicionais, cujos tempos de reação característicos nem sempre seguem os observados no solo e nos mercados econômicos.  

Nos últimos anos uma nova forma de se fazer ciência vem ganhando força e cada vez mais novos adeptos. Chamada de "Ciência Cidadã", ela vem ajudando a mudar a forma como a ciência hoje é feita. Tendo como ponto de partida as novas tecnologias de computação e de internet, os primeiros projetos de ciência cidadã moderno foram os chamados de computação voluntária. Na computação voluntária, cidadãos conectam seus computadores à internet e compartilham o tempo de processamento de suas máquinas com projetos que precisavam de grande capacidade computacional. Exemplos de iniciativas de computação voluntária com mais de duas décadas são os projetos \textit{Great Internet Mersenne Prime Search} \textbf{\textit{GIMPS}}\footnote{\url{http://www.mersenne.org/}} e \textbf{\textit{Distributed.net}}\footnote{http://www.distributed.net/}\cite{Anderson1999,AndersonCKLW02,Hayes1998}. Comum a ambos é a utilização da plataforma de computação voluntária BOINC \cite{Anderson1999}, desenvolvida na Universidade da Califórnia em Berkeley. Com o BOINC, a computação voluntária ganhou força e popularidade \cite{anderson2003public}. 

Mais recentemente, outra forma de realizar ciência cidadã - pensamento voluntário - surgiu e se popularizou. Nesta forma de ciência cidadã, voluntários emprestam as suas capacidades cognitivas a projetos científicos. Assim, o projeto GalaxyZoo \cite{oxfordgalaxy2007} ganhou grande notoriedade por conseguir atrair dezenas de milhares de cidadãos leigos, que realizaram milhões de tarefas de classificação de galáxias, com desempenho igual a de astrônomos profissionais. Onde a computação voluntária necessita apenas de uma conexão para interligar os computadores e disponibilizar potência computacional ociosa para auxiliar projetos, no pensamento voluntária o poder cognitivo do cidadão é utilizado em ações que ainda não são fáceis para uma máquina realizar de modo eficiente, como o reconhecimento de padrões. 

Uma terceira forma de realizar projetos de ciência cidadã vem se fortalecendo ao longo dos últimos anos. Em vez de utilizar a capacidade cognitiva ou de computação de voluntários, alguns projetos necessitam que voluntários coletem dados. Um exemplo dos mais antigos de ciência cidadã é o projeto de contagem de pássaros Christmas Bird Count, que está em sua 115\textdegree edição e ainda cativa milhares de pessoas. Estes projetos de ciência cidadã são chamados de sensoriamento voluntário (SV).

\section{Objetivos}
\label{ch:objetivos}

O projeto ForestWatchers (FW) é o primeiro projeto que propõe-se a integrar e utilizar estas três formas de fazer ciência cidadã na tarefa de monitorar as florestas tropicais do planeta. Neste contexto, o objetivo da presente dissertação é o desenvolvimento e teste do módulo de sensoriamento voluntário do projeto FW. Para este fim, este módulo de sensoriamento voluntário deverá integrar-se aos módulos já desenvolvidos (Figura \ref{fig:estrutura_atual}), adicionando à arquitetura existente a capacidade de coletar dados \textit{in-situ}, utilizando-se de dispositivos móveis de voluntários.

\subsection{Objetivos Específicos}
\label{ch:objetivos:especificos}

Os objetivos específicos desta pesquisa são:

\begin{enumerate}

    \item Propor, desenvolver e testar o módulo de sensoriamento voluntário do projeto ForestWatchers para o monitoramento de florestas tropicais;
    
    \item Testar o módulo de sensoriamento voluntário em condições reais de utilização;

    \item Integrar o módulo de sensoriamento voluntário aos módulos já existentes do FW.

\end{enumerate}

\section{Organização do Documento}
\label{ch:organizacao}
Este documento está organizado da seguinte forma: No Capítulo \ref{ch:monitoramento_florestas}, é feita a revisão bibliográfica das ferramentas de monitoramento de florestas criado pelo INPE e suas metodologias. Uma revisão do tópico de ciência cidadã é abordado no Capítulo \ref{ch:ciencia_cidada}, onde é realizada uma comparação com as pesquisas científicas realizadas por voluntários antigamente e nos tempos atuais, conhecida por ciência cidadã moderna. No Capítulo \ref{ch:forestwatchers}, é apresentado o projeto ForestWatchers, a definição do projeto, a metodologia empregada e as aplicações feitas por este. As metodologias e resultados deste trabalho são apresentados no Capítulo \ref{ch:metodologia} e \ref{ch:resultados}, respectivamente. Para finalizar, as conclusões são feitas no Capítulo \ref{ch:conclusoes}.

\chapter{Monitoramento de Florestas}
\label{ch:monitoramento_florestas}

Por mais de duas décadas, o Brasil vem utilizando imagens de satélites (Figura \ref{fig:comparacao_resourcesat_modis}) para realizar o monitoramento da Amazônia \cite{Monteiro2008}. Estes sistemas, desenvolvidos pelo INPE, tornaram o Brasil uma referência mundial na área \cite{Tollefson2012a}. \citeonline{Kintisch2007} afirma que esse sistema é motivo de admiração mundial por ser capaz de informar anualmente as estimativas de taxas de desmatamento na Amazônia, além de emitir alertas semanais para as autoridades pertinentes. Os principais sistemas utilizados pelo INPE na tarefa de monitorar o desmatamento são descritos nas seções a seguir.

\section{PRODES}
\label{ch:prodes}

Em 1988, o Projeto de Monitoramento do Desmatamento na Amazônia Legal (PRODES) foi estabelecido para fornecer informações sobre a dinâmica anual do desmatamento de cobertura florestal na Amazônia Legal. As estimativas geradas pelo PRODES são anuais devido à complexidade e ao detalhamento necessários para o cálculo da área desmatada. Essas estimativas se baseiam em mapeamento detalhado com um grande conjunto de imagens do tipo LANDSAT (ou equivalente) , que cobrem a Amazônia com baixa frequência temporal (16 e 26 dias, Figura \ref{fig:swath_width_LANDSAT-NASA}) e com resolução espacial entre 20 e 30 metros. Esses sensores são capazes de mapear desmatamentos cujas áreas sejam superiores a $6,25$ hectares \cite{Monteiro2008}.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figuras/swath_width_LANDSAT-NASA.jpg}
    \caption{Faixa de cobertura diária realizado pelo LANDSAT, ilustrado no continente Norte Americano. Para obter toda a extensão amazônica é necessário de 16 a 26 dias, dependendo das condições climáticas do local.  }
    \FONTE{\citeonline{Nasa:swath_landsat:2015}}
    \label{fig:swath_width_LANDSAT-NASA}
\end{figure}

\subsection{Metodologia}
\label{ch:prodes_metodo}

Para realizar o cálculo da taxa de desmatamento, as imagens são selecionadas de modo a obter a menor cobertura de nuvens possível, melhor visibilidade com uma adequada qualidade radiométrica\footnote{A resolução radiométrica é dada pelo número de níveis de cinza, usados para expressar os dados coletados pelo sensor. Quanto maior o número de valores, maior é a resolução radiométrica \cite{Monteiro2008}.} e com a data de aquisição das imagens próxima ao período de referência para o cálculo da taxa de desmatamento. Porém, considerando o histórico climatológico da Amazônia, a maioria das imagens não se apresentam livres de nuvens. Por isso é necessário utilizar mais de uma imagem (inclusive de outros satélites) para compor as cenas, formando um mosaico (Figura \ref{fig:prodes_mosaico}). 

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figuras/mosaico_landsat-prodes.png}
    \caption{ Mosaico formado por imagens LANDSAT a serem utilizadas no sistema PRODES.}
    \FONTE{\citeonline{Monteiro2008}}
    \label{fig:prodes_mosaico}
\end{figure}

Após a seleção das imagens, a próxima etapa envolve transformar seus dados radiométricos em componentes de cena (vegetação, solo e sombra), utilizando o Modelo Linear de Mistura Espectral (MLME) \cite{Monteiro2008}. As bandas 3, 4 e 5 do sensor TM são utilizadas para estimar a proporção dos componentes solo, vegetação e sombra para cada pixel, formando um sistema de equações lineares que pode ser solucionado pelo método dos mínimos quadrados ponderados. O resultado desse modelo linear é uma imagem fração, onde se tem três bandas sintéticas com os valores proporcionais de vegetação, solo e sombra. A segmentação\footnote{Segmentação de imagem é uma técnica de agrupamentos de dados onde características espectrais semelhantes são agrupadas \cite{Monteiro2008}.} da imagem fração é então realizada, ajustando-se os limiares de similaridades e de área. 

Um algoritmo de classificação não-supervisionado de agrupamentos de dados trata as imagens segmentadas, classificando-as de acordo com as classes definidas pelo banco de dados. Como resultado tem-se uma nova imagem \textit{raster}. Então, um fotointerprete tem a tarefa de analisar os polígonos temáticos gerados, tomando a decisão se esses devem ser aceitos ou reclassificados. Uma vez essa imagem aceita, uma máscara de desmatamento contendo as áreas de corte raso já detectados é gerada. Essa máscara será utilizada para eliminar desmatamentos antigos, impedindo que sejam identificados novamente.

\section{DETER}
\label{ch:deter}

Devido ao tempo necessário para gerar os resultados e por observar apenas áreas de corte raso, o PRODES não pode ser utilizado como um sistema de prevenção de desmatamento. Portanto, a partir de 2004 o Sistema de Detecção de Desmatamento em Tempo Real (DETER) foi implementado para realizar o monitoramento contínuo do desmatamento e da degradação florestal. Esse sistema foi criado para atender ao Governo Federal no Plano de Ação para a Prevenção e Controle do Desmatamento na Amazônia Legal. O principal objetivo desse sistema é de fornecer informações sobre o local e a dimensão aproximada de ocorrências de mudanças na vegetação de modo a agilizar a fiscalização \cite{Monteiro2008}. 

\subsection{Metodologia}
\label{ch:deter_metodo}

As imagens utilizadas por esse sistema são obtidas pelo sensor MODIS (a bordo dos satélite TERRA e ACQUA da NASA), que cobre a Amazônia aproximadamente a cada um dia e meio (Figura \ref{fig:swath_width_MODIS-TERRA}. Essa alta resolução temporal reduz as limitações de observação impostas pela cobertura de nuvens da região. Com a máxima resolução espacial limitada em aproximadamente $250$ metros, as imagens desses sensores permitem a detecção de desmatamentos apenas para áreas maiores do que $25$ hectares. O objetivo do DETER é de fornecer indicadores para fiscalização a cada 15 dias, quando as condições de observação são favoráveis. Esse sistema observa diversos estágios de desmatamento para emitir seus alertas, como o de corte raso, degradação florestal de intensidade alta, média e baixa, sendo o último mais difícil devido a resolução das imagens do sensor MODIS \cite{Monteiro2008}.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figuras/swath_width_MODIS-TERRA.jpg}
    \caption{Faixa de cobertura diária obtida a cada sobrevoo. Para obter toda a extensão amazônica é necessário em média um dia e meio.}
    \FONTE{\citeonline{Nasa:swath:2015}}
    \label{fig:swath_width_MODIS-TERRA}
\end{figure}

A aquisição das imagens é feita de forma rápida, uma vez que que o DETER utiliza os produtos baseados em \textit{granules}\footnote{Granules são produtos gerados de uma área particular. Granules não cobrem todo o globo.} dos subconjuntos de resposta rápida da NASA. Esses dados encontram-se prontos\footnote{\url{https://earthdata.nasa.gov/data/near-real-time-data/rapid-response/}} para serem utilizados, pois já foram processados, disponibilizados em GeoTIFF, RGB equivalente, no formato de 8-bits e geograficamente projetados \cite{Nasa:swath:2015,Nasa:swath_landsat:2015}. 

Essas imagens são então carregadas no Sistema de Processamento de Informações Georreferenciadas (SPRING) para que outros processamentos sejam feitos. Nesta etapa, o especialista necessita aplicar um modelo de mistura para separar o que é floresta, solo ou água (ou sombra). Essa etapa é feita selecionando-se certos \textit{pixels} com uma resposta espectral particular. Então, cada imagem é segmentada e classificada. Após a classificação das imagens, o especialista aplica as máscaras dos desflorestamentos anteriores e de hidrografia, com a finalidade de esconder os desmatamentos já conhecidos assim como outras características. 

Na última etapa, o especialista corrige os resultados da segmentação automática, pixel a pixel. As vezes é possível que as etapas de classificação e segmentação possam ser colocados de lado, pois o especialista pode extrair todas as informações baseando-se apenas em sua experiência olhando para as imagens do satélite, munido dos arquivos geográficos de desflorestamento prévio e hidrografia.

\begin{figure}[htb]
\includegraphics[width=0.485\textwidth]{figuras/COMPARE_RESOURCESAT.png}
\hfill
\includegraphics[width=0.485\textwidth]{figuras/COMPARE_MODIS.png}
\caption{Comparação de diferentes resoluções espaciais. À esquerda, uma imagem RESOURCESAT com 23,5 m por pixel. À direita, uma imagem MODIS com 250 m por pixel.}
\label{fig:comparacao_resourcesat_modis}
\end{figure}

\chapter{Ciência Cidadã}
\label{ch:ciencia_cidada}

Ciência cidadã é o termo usado para designar projetos no qual voluntários, muitos sem nenhum treinamento científico específico, participem de ou gerenciem certas atividades científicas, tais como a realização de observações, medições ou computação \cite{SoaresSant:2011:EnPoAt}. 

Através do voluntariado de pessoas comuns, conhecidas como cientistas cidadãos, projetos científicos conseguem obter um quadro maior de colaboradores \cite{Cohn.2008}, um fator importante em projetos grandes, agilizando o processo de aquisição e divulgação dos resultados. Segundo \citeonline{Silvertown2009}, o cientista cidadão é um voluntário que coleta ou processa dados como parte de uma pesquisa científica. Cientistas cidadãos não são responsáveis, necessariamente, por analisar ou publicar artigos científicos; em geral estes desempenham tarefas simples, mas de grande importância para a conclusão dos trabalhos científicos. Nas últimas décadas, projetos científicos baseados em ciência cidadã ganharam notoriedade, porém esta abordagem não é nova para a comunidade científica. 

Realizar pesquisas cientificas utilizando-se da colaboração de diversos indivíduos não é novidade, antigamente diversos cientistas realizavam suas pesquisas desta forma. Já no século XIX, Charles Darwin em "A Origem das Espécies" \citeonline{darwin-origin-of-species-1859} contou com a ajuda de mais de dois mil colaboradores e pesquisadores de diferentes áreas.  De acordo com o projeto \textit{Darwin Correspondences}\footnote{\url{http://www.darwinproject.ac.uk/}}, Darwin trocou mais de 7.500 das cartas com correspondentes durante sua pesquisa \cite{DarwinProject_Correspondents}. Os conteúdos destas cartas variavam de anotações científicas sobre algumas espécies, o que requeria um aparato profissional, até simples observações, que vieram a colaborar com teoria da evolução das espécies. 

Naquela época, as cartas demoravam meses para serem recebidas e lidas, o processo de responder uma carta e obter um novo retorno da mesma pessoa, chegava a levar anos para acontecer. A falta de infraestrutura e de tecnologias, tornavam a tarefa de entregar uma carta, que hoje em dia é simples e comum, um trabalho difícel e lento. Naquela época, o serviço de correspondência era feito por mensageiros a pé, a cavalo ou através de charretes, tendo navios à vela para transporte marítimo das correspondências. \citeonline{Hyde1891} relembra que para a determinada época, estes serviços eram caros e não acessível para todos, o que dificultava ainda mais o compartilhamento de ideias. Em 1840, com a grande reforma de postagem britânica, \textit{Uniform Penny Postage}\footnote{A reforma realizada pela \textit{Royal Mail} do Reino Unido cobrava apenas um \textit{Penny}, menor moeda do sistema monetário da época, para entregar as cartas indiferente da distância \cite{BritishPostalMuseum2015,Hyde1891}.}, houve uma maior difusão e uso dos serviços, elevando o envio de cartas de 82.500.000 para 169.000.000 em um ano, mais que o dobro \cite{Hyde1891}.

\citeonline{Zimmer2011}, comenta que um projeto de ciência cidadã como o Evolution MegaLab \cite{Silvertown2011} seria possivelmente uma das formas de Darwin fazer ciência hoje. Neste projeto, mudanças evolucionárias são observadas em tempo real por diversos colaboradores, que coletam e enviam informações sobre as cores das cascas de duas espécies de caramujos, \textit{Cepaea nemoralis} e \textit{C. hortensis}.

Mais recentemente, um projeto da universidade de Oxford irá investigar o envolvimento do público na ciência do século XIX ao XXI. Este projeto receberá o financiamento de quase 2 milhões de libras para realizar seus estudos \cite{conscicom2014}, e deverá ajudar a conceber e desenvolver novas ferramentas para troca de informações entre cientistas profissionais e legiões de voluntários \cite{Leicester2013}. 

\section{Ciência Cidadã Moderna}
\label{ch:ciencia_cidada_moderna}

O projeto considerado um dos primeiros de ciência cidadã moderno é o \textit{Christmas Bird Count}. Um projeto antigo e que ainda encontra-se em atividade, o Christmas Bird Count procura contar as diferentes espécies que existem na América do Norte, suas eventuais mudanças de habitat, entre outras informações. O projeto foi idealizado em 1900 por Frank Chapman, um famoso ornitólogo do Museu Americano de História Natural, como uma atividade alternativa ao evento de caça aos pássaros existente na época. Chapman publicou diversos livros com os resultados obtidos por este projeto com a ajuda de milhares de voluntários. Os voluntários seguem diversas regras para conduzir a pesquisa durante os 20 dias em que as observações são feitas, de 14 de dezembro a 5 de janeiro de cada ano, só podem ser contabilizados os pássaros que forem avistados ou ouvidos em um diâmetro de 24 km, moradores próximos a estas áreas podem utilizar bebedouros para pássaros para atrair mais espécies e contabilizá-los \cite{Silvertown2009}. Em uma contagem recente, milhares de observadores relataram mais de $63$ milhões de pássaros. 

Hoje, o centro de pesquisa que deu origem a este projeto é considerado um dos maiores centros especializados em ciência cidadã com diversos estudos em biologia. Cientistas do laboratório Cornell de Ornitologia da universidade de Cornell, líderes no estudo e conservação dos pássaros, rastreiam projetos que utilizam ciência cidadã para realizar seus estudos. Estes acreditam que trabalhar com cientistas cidadãos é um fenômeno em expansão em todo o mundo \cite{Cohn.2008}. Este laboratório conta com uma comunidade de aproximadamente 200 mil participantes em projetos de ciência cidadã.

Ainda há dúvidas se os projetos de ciência cidadã possam gerar resultados confiáveis, uma vez que muitos dos voluntários engajados nas atividades científicas não possuem conhecimento nem mesmo familiarização com as ferramentas de coleta. Esta é uma questão muito pertinente e recorrente do meio. Há evidências \cite{Silvertown2009,Silvertown2011,Cohn.2008} que estes dados produzidos por cidadãos comuns são confiáveis. Para garantir a confiança nestes dados é necessário que algumas medidas sejam seguidas.

Para alguns tipos de projetos, \citeonline{Cohn.2008} defende que os voluntários devam possuir algum tipo de treinamento básico, para que os dados sejam coletados conforme o solicitados pelos cientistas, assim diretrizes devem ser definidas. Parte dessas diretrizes deve limitar o trabalho do voluntário, especificando um determinado foco de coleta, por exemplo. Esta especificação evita diversos ruídos nos dados e ao comparar a coleta feita entre os voluntários, os dados seguirão a mesma semântica, facilitando a verificação de erros. Há relatos que projetos anteriores baseados em ciência cidadã, possuíam resultados variados por causa destes ruídos, ao invés de dados exatos \cite{Cohn.2008}. Solicitar que os voluntários desempenhem trabalhos simples auxilia na exatidão dos dados. 

\citeonline{Silvertown2009} enumera três fatores cruciais para o aparecimento de projetos de ciência cidadã nos últimos anos. Primeiramente, a internet como meio de disseminar informações e adquirir dados do público, assim como a tecnologia dos \textit{smartphones}, onde mais e mais aplicativos utilizam diversos sensores para coletar diferentes dados. Segundo fator se deve aos cientistas profissionais perceberem que voluntários são uma fonte sem custos de trabalho e habilidades pessoais como também de poder computacional, projetos que requerem adquirir diversos dados ao longo do globo, necessitam de ajuda, podendo ser de voluntários, para se obter sucesso. Terceiro fator, financiadores de projetos científicos procuram beneficiar projetos que utilizam cientistas cidadãos em seus trabalhos.

Com o aparecimento destes novos projetos, a ciência cidadã moderna pode ser classificadas em três formas, conforme o nível de envolvimento do voluntário e a tecnologia utilizada no projeto (Figura \ref{fig:pt_citizen_science}).

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figuras/pt_citizen_science.png}
    \caption{A ciência cidadã pode ser classificadas em três formas: computação voluntária, onde os voluntários doam o poder computacional de suas máquinas para pesquisas científicas; pensamento voluntário utilizado em projetos que requerem a cognição dos voluntários, como classificação de imagens; e sensoriamento voluntário onde a captação de dados é crucial para a pesquisa.}
    \label{fig:pt_citizen_science}
\end{figure}

Estas formas serão introduzidas a seguir.

\section{Computação Voluntária}
\label{ch:computacao_voluntaria}

Recentemente, o número de projetos que se beneficiam de ciência cidadã está aumentando, cada dia há novos projetos surgindo. Estes projetos chamados de ciência cidadã moderno estão se tornando frequente por causa da acessibilidade das tecnologias atuais, o que não requer aparatos especializados para realizar as pesquisas. Como mencionado anteriormente, as informações que \citeonline{Darwin1859} utilizou em suas pesquisas foram enviadas através de cartas que demoravam muitos meses para chegar a seu destinatário. Hoje, com o avanço da internet, voluntários em diferentes partes do mundo podem fornecer diferentes tipos de dados a uma pesquisa. Seja por dispositivos móveis, que uma vez ligados a internet podem fornecer dados de qualquer lugar, ou então por meio de computadores. 

Na década de 80, a internet ainda era apenas um embrião e poucos tinham acesso à rede. Existiam menos de 200.000 servidores espalhados no mundo. Até então não existiam páginas para serem navegadas, a principal forma de troca de mensagem era através de e-mail, criado em 1977 \cite{HistoryOfInternet:David,HistoryOfInternet:Anthony}, outros meios eram por TELNET e IRC, apenas. Só no início da década de 90 que as primeiras páginas de internet foram criadas, após a definição do \textit{WWW}\footnote{World Wide Web} criado por \citeonline{berners1992world}. A internet estava tornando-se popular, com seus aproximados 1 milhão de servidores e suas 50 páginas de internet \cite{HistoryOfInternet:Anthony}.

Com a popularização da internet, iniciou-se a aparição de projetos notáveis da ciência cidadã moderna. Os computadores da época eram caros e possuíam pouco poder computacional, apenas grandes indústrias e universidades tinham acesso a máquinas de grande desempenho. Neste período, surgiram os primeiros projetos de computação voluntária, onde os voluntários doavam o tempo de processamento ocioso de suas máquinas a projetos que necessitavam de grande poder computacional para trabalhar em cima dos seus dados. O conceito desta forma de projeto era de dividir a grande massa de dados existente em pequenas porções que fossem possíveis para os voluntários efetuar downloads, visto que naquela época não havia internet de banda larga. A forma de conexão à internet ainda era discada e o modem mais rápido deste período era o de 56 Kbps\footnote{56 kilobits por segundo} \cite{AndersonCKLW02}.

No meio da década de 90, surgiram os projetos \textbf{\textit{GIMPS}}\footnote{\textit{\url{http://www.mersenne.org/}-Great Internet Mersenne Prime Search}} e \textbf{\textit{Distributed.net}}\footnote{http://www.distributed.net/}\cite{Anderson1999,AndersonCKLW02,Hayes1998}.

\textit{GIMPS} foi o primeiro projeto de computação voluntária de grande porte a ser realizado, \textit{GIMPS}, tinha como objetivo encontrar números primos de Mersenne, nome dado em homenagem ao estudioso Marin Mersenne da teoria dos números. A formula destes números equivale  $ M_n = 2^n -1 $, onde $n$ é um número natural. O desafio de descobrir números de Mersenne está diretamente ligado ao fato destes números serem exponenciais, tendo assim milhares de dígitos em sua composição. Até 1996, início do projeto \textit{GIMPS}, apenas 34 números primos de Mersenne eram conhecidos, logo no primeiro ano do projeto foram descobertos mais dois  números, $ M_{1398269} $ e $M_{2976221}$. O primeiro número possui $852.365$ algoritmos, o segundo $1.814.262$, uma operação que seria impossível para ser realizada por uma pessoa. Ambos foram descobertos na primeira versão do software disponibilizado pelo projeto, sendo calculado por um computador \textit{Pentium} 90 MHz e \textit{Pentium} 100MHz, respectivamente. Hoje, há o conhecimento de 48 números de Mersenne, sendo o último número descoberto o $M_{57885161}$ com $17.425.170$ dígitos em 2013, desde o início do projeto foram descobertos 14 destes números \cite{Marsenne:Primes,Hayes1998}.

A \textit{Distributed.net}, lançado em 1997, tinha o principal objetivo de quebrar a criptografia gerada pela empresa RSA, para o desafio \textit{RSA Secret-Key Challenge} que correspondia a uma chave de 56-bit e possuía uma recompensa de $10.000,00$ dólares. O projeto criado por Earle Ady e Christopher G. Stach II, contava com a colaboração de mais de $300.000$ voluntários utilizando o tempo de seus computadores realizando um ataque de Força Bruta\footnote{Força Bruta é a forma de tentar obter a a resposta de uma senha através de inúmeras tentativas.} em cima de parte do código disponibilizado para o desafio. Em 250 dias a chave foi descoberta, utilizando um poder computacional equivalente a 26 mil \textit{Pentium} 200 MHz. Outro desafio com uma chave de 64-bit também foi concluído após 4 anos e o prêmio pago. A empresa de segurança RSA, havia dito que para quebrar uma chave de 64-bit, seria necessário mais de 100 anos testando todas as possibilidades e combinações. Atualmente o projeto está focado em quebrar uma chave de 72-bit \cite{distributed.net:online,Distributed.net:wired}. 

Em 1999, \citeonline{AndersonCKLW02} iniciou um dos primeiros e mais bem sucedido projeto de ciência cidadã. O objetivo deste projeto era de encontrar vida inteligente no espaço, através da análise de sinais de rádios captadas do espaço, \textit{SETI@Home}. Porém para conseguir analisar esses sinais, o projeto contou com o uso de diferentes computadores, espalhados pela internet formando um grande sistema destribuído de processamento. Os voluntários que se cadastravam no sítio podiam fazer download de um aplicativo que só era ativado quado o computador estava em modo ocioso. O aplicativo recebia pacotes de sinais a serem analisados e no fim do processamento enviava os resultados obtidos ao servidor do projeto.

\section{Pensamento Voluntário}
\label{ch:pensamnto_voluntario}
\citeonline{Anderson1999}, a frente do projeto \textit{SETI@Home}, iniciou o desenvolvimento de uma nova plataforma computacional para diminuir as barreiras que ele havia encontrado ao longo do desenvolvimento do seu último projeto, viabilizando assim novas iniciativas para utilizar computação voluntária de forma rápida e sem grandes conhecimentos de computação. Chamada de BOINC\footnote{Berkeley Open Infrastructure for Network Computing}, seu objetivo era de avaliar a exatidão e veracidade dos dados antes de enviá-los aos servidores dos projetos \cite{anderson2003public}. Esta ferramenta já foi utilizada por mais de 150 projetos, tendo atualmente 70 projetos online. Estes fatos só foram alcançados pela acessibilidade que novos projetos do tipo de computação voluntária tiveram com a criação da nova ferramenta e também pela visibilidade que a ferramenta deu aos projetos deste porte.

Além da ferramenta \textit{BOINC} realizar verificações redundantes para melhorar a exatidão dos resultados, esta também classificava os usuários e mantinha um histórico da pontuação de cada usuário conforme seu comprometimento em relação aos projetos. Na página da ferramenta, existem diversas estatísticas dos projetos em andamento, estas estatísticas são atualizadas dinamicamente conforme os resultados são submetidos pelos voluntários. Uma vez que os novos resultados são submetidos e aprovados, cada voluntário tem o valor da sua contribuição ao projeto calculado novamente. Tendo assim um sistema de créditos, que pontua a participação dos voluntários, destacando os que mais contribuem. Este é considerado o sistema de recompensa dos usuários, levando o projeto a ter cada vez mais voluntários contribuindo com a performance da sua máquina para ganhar notoriedade \cite{Anderson1999}.

No fim da década de 90, \citeonline{dinucci1999fragmented} cunhou o termo \textit{Web 2.0} dizendo que a internet até então não tinha mostrado o seu real potencial. As páginas eram simplesmente recursos estáticos onde a navegação era composta de uma simples requisição a este recurso e o recurso era então exibido na tela dos computadores da época. A revolução da \textit{Web 2.0} seria marcada pela interatividade do conteúdo, permitindo a qualquer pessoa utilizando um computador ou dispositivo móvel, não mais carregar um simples recurso estático, mas sim o poder de interagir com este recurso, expressando ideias e adicionando novas informações a \textit{Web}. Diversas novas ferramentas foram criadas nesta nova era. Diferentes tipos de \textit{blogs}, \textit{wikis} e páginas de internet repletos de conteúdos dinâmicos.

Com a possibilidade de conteúdo dinâmico e a interação dos usuários, surgiram novos tipos de projetos que passaram a utilizar a capacidade cognitiva dos voluntários para analisar visualmente determinados dados e em função destes tomar ações. 

Um dos primeiros projetos de pensamento voluntário foi criado para detectar pequenas partículas de poeira interestelar coletada pela missão \textit{Stardust} da NASA, lançada em 1999 \cite{Stardust:Mission}. Andrew Westpahl, o idealizador do projeto \textit{Stardust@Home} teve a ideia de utilizar a cognição dos usuários para substituir a falta de uma tecnologia de reconhecimento de padrão capaz de encontrar as partículas minúsculas coletada pela missão. Westpahl estimou que levaria mais de um século para sua equipe poder atingir o objetivo do projeto sem a ajuda dos voluntários. Para encontrar as partículas, foi disponibilizado no início do projeto em 2006, 1,6 milhões de imagens na página do projeto. Estas imagens recriam a experiência que um cientista teria se estivesse analisando as amostras atrás de partículas através de um microscópio, estabelecendo uma melhor imagem pelo ajuste do seu foco. Estas 1,6 milhões de imagens foram feitas para simular esta função e são chamadas de ``filmes de foco''. Assim diversas imagens foram feitas de um determinado ponto mas utilizando posições diferentes para se ter uma melhor nitidez da imagem. É função do voluntário verificar se esta imagem está bem focada, verificando a nitidez das imagens disponibilizadas e se há alguma partícula presente em alguma destas imagens\cite{Hand2010}. Caso não exista nenhuma imagem focada, o voluntário deve informar através do sítio esta situação, assim como outras diversas situações que podem acontecer. Para conhecer essas determinadas situações, os voluntários necessitam realizar um treinamento antes de iniciar o seu trabalho de voluntário efetivamente, neste treinamento há dicas e orientações de como proceder. Este tipo de treinamento de qualificação é muito comum em projetos de ciência cidadã \cite{Silvertown2009,Anderson1999}.

Apesar do projeto \textit{Stardust@Home} possuir o sufixo \textit{@Home}, este não utiliza a ferramenta BOINC, idealizada por \citeonline{anderson2003public}. Este sufixo é apenas uma homenagem aos projetos de ciência cidadã. Contudo, \citeonline{Anderson1999} estudou o projeto e idealizou uma nova ferramenta para tornar projetos de pensamento voluntário mais comuns, assim como o uso da ferramenta BOINC. O resultado desta pesquisa foi a plataforma BOSSA\footnote{\url{http://boinc.berkeley.edu/trac/wiki/BossaIntro}}. Trata-se de um \textit{middleware} responsável por dividir o trabalho em tarefas menores e atribuí-las aos voluntários, realizando verificações do nível de assertividade das respostas dadas pelos voluntários através de redundância das tarefas. 

Em 2007, iniciou-se o projeto \textit{GalaxyZoo} com o objetivo de classificar imagens de galáxias. As imagens captadas por um telescópio robótico, \textit{Sloan Digital Sky Survey}\footnote{http://www.sdss.org/} era apresentadas para os voluntários e estes tinham que decidir se a imagem continha alguma galáxia e, se afirmativo, qual era a sua forma (elíptica ou espiral). Se fosse espiral, ainda havia uma última pergunta, qual o sentido da sua rotação\cite{Hand2010}. Pelo número de imagens que deveriam ser classificadas, os cientistas envolvidos acreditavam que iria demorar mais de 2 anos para que todas as imagens fossem classificadas\cite{GalaxyZooAbout}. Porém, com apenas um dia de funcionamento, o \textit{GalaxyZoo} conseguiu reunir 35 mil voluntários que fizeram aproximadamente 1.5 milhões de classificações. O projeto classificou perto de um milhão de galáxias utilizando-se de mais de 150 mil voluntários. Em sua segunda versão, o GalaxyZoo contou com mais de 200 mil voluntários para classificar de forma mais detalhada 300 mil galáxias previamente classificadas \cite{willett2013galaxy}. 

\textit{Rosseta@Home} é outro importante projeto de ciência cidadã. Quando criado em 2005, este projeto seguia a mesma tendência do \textit{Seti@Home} assim como os demais projetos da família \textit{@Home}, ser baseado em computação voluntária. O objetivo deste projeto é de utilizar o grande poder computacional reunido para prever o enovelamento de proteínas, um processo químico em que a estrutura de uma proteína assume a sua configuração funcional, podendo assim desenvolver novas proteínas para combater diversas doenças. Como os demais projetos da família, os voluntários tinham que executar o instalador do projeto utilizando o BOINC e este só iria entrar em funcionamento quando o computador estivesse ocioso, em modo de protetor de tela. Porém, diversos e-mails foram enviados ao projeto de voluntários que queriam contribuir mais, dizendo ser possível obter melhores resultados se eles pudessem interagir com o modelo de proteína que estava aparecendo ali no protetor de tela. 

Com isto em mente, David Baker desenvolveu um novo projeto de pensamento voluntário com características de um jogo através da internet, onde os voluntários são os jogadores e precisão achar as melhores soluções para os desafios, utilizando o enovelamento de proteínas \cite{Hand2010}. \textit{Foldit}, lançado em 2008, provou que os voluntários conseguem realizar um melhor trabalho do que um computador. Este foi um dos primeiros trabalhos a envolver tanto computação voluntária quanto o pensamento voluntário \cite{Cooper2010}.

Um dos resultados mais significativos, foi alcançado pelos jogadores do projeto \textit{Foldit} em 2011, onde os voluntários resolveram um problema proposto pelos pesquisadores em apenas 3 semanas. Os cientistas lançaram o desafio a partir do instante em que os métodos automáticos começaram a não retornar bons resultados. Ao analisar os resultados dos jogadores, observaram que estes eram suficientemente bons para encontrar uma rápida solução \cite{Khatib2011}.

\citeonline{mcgonigal2011reality} sugere que os problemas atuais poderiam ser solucionados efetivamente de outra forma, através dos jogos. Conscientizando pessoas dos problemas reais e inserindo os diversos problemas no contexto de jogos, os jogadores iriam buscar soluções para estes desafios. Diversos pesquisadores sugerem que construir projetos de ciência com a temática na forma de jogos poderiam atrair ainda mais os voluntários e resolver ainda mais rápido os desafios empregados \cite{Silvertown2009,Hand2010,Khatib2011,Anderson1999,Pereira:2013:NoInUs,Cooper2010,Mansell2012}.

\section{Sensoriamento Voluntário}
\label{ch:sensoriamento_voluntario}

As duas formas de ciência cidadã discutidas anteriormente têm suas vantagens conforme a necessidade do método de pesquisa científica que irá ser executada. Computação voluntária tem maior vantagem para as atividades científicas que requerem grande poder computacional, avaliando grandes quantidades de dados, o que levariam horas para uma pessoa realizar. Já o pensamento voluntário, mostra-se mais eficaz em atividades que requerem o poder cognitivo dos voluntários, como detecções de padrões utilizando inspeção visual.

Algumas vezes, os dados disponíveis para projetos científicos não são suficientes e a coleta de outros tipos de medidas se faz necessária. Adquirir novas fontes de dados não é um trabalho simples pois necessita equipes capazes de efetuar as coletas científicas conforme padrões exigidos e ferramentas adequadas para tal.
Assim, a realização desta tarefa, se feita apenas pelos cientistas envolvidos diretamente com o projeto, pode se tornar custosa e demorada. Portanto, uma alternativa viável é a utilização de sensoriamento voluntário onde voluntários contribuem com dados, sejam anotações de observações, captação de imagem ou sons de um ambiente. A tecnologia atual permite soluções de menor custo para coletar diversos tipos de dados para serem utilizados em projetos científicos.

O sensoriamento voluntário é uma junção de Informação Geográfica Voluntariada (IGV), termo cunhado \citeonline{Goodchild2007} e usado para descrever as tarefas realizadas por voluntários ao fornecer dados complementares a determinadas localizações geográficas com a finalidade de enriquecer a base de dados, com sensoriamento móvel \cite{Lane2010}, onde pesquisas são conduzidas através de aparelhos móveis dos voluntários utilizando os sensores do dispositivo. 

\subsection{Informação Geográfica Voluntariada}
\label{ch:informacao_geografica_voluntariada}

\citeonline{Goodchild2007} categoriza de \textbf{Informação Geográfica Voluntariada (IGV)} o fenômeno que vem atraindo cidadãos de toda parte, a criação de informações geográficas. Tarefa que antigamente era de uso exclusivo das agências oficiais responsáveis por realizar cartografias dos países, porém com o avanço da tecnologia, qualquer pessoa pode ter acesso a ferramentas de edição de mapa online e colaborar com alguma informação geográfica. Seja esta específica sobre um determinado prédio, dado sua latitude e longitude, como também por vastos terrenos, ao descrever uma cidade. Este recente paradigma representa uma dramática inovação e certamente terá grandes impactos aos sistemas de informação geográfica.

Este conceito de criação de dados geográficos por voluntários vem sendo amplamente estudado por diferentes frentes. Para a indústria, o desenvolvimento de plataformas baseado em web onde os usuários possam enviar seus dados. Para o governo, o conceito é estudado para possíveis aplicação em sistemas de alerta em caso de surtos de doenças e o constante monitoramento dos impactos ambientais. Para pesquisadores acadêmicos em como adaptar ambientes de sistemas de informação geográficos para utilizar, armazenar e analisar os dados coletados por voluntários \cite{elwood2008volunteered}.

Um marcante projeto de informação geográfica voluntariada, \textit{Wikimapia}, é referência nesta categoria, onde voluntários podem contribuir com novas informações geográficas simplesmente escolhendo um local (através de uma coordenada geográfica) e complementando a informação local \cite{Wikimapia:online}. Este projeto possui um objetivo ambicioso de descrever todo o globo terrestre com o máximo de informações geográficas úteis reunidas através do uso de voluntários, organizá-las e disponibilizá-las para diversos outros usos públicos das informação. Através de uma interface simples, Figura \ref{fig:wikimapia}, para que os voluntários que não possuam experiências com edição de mapas possam também, de forma rápida e intuitiva, colaborar com o projeto. Foi lançado em maio de 2006 como uma ferramenta similar a Wikipédia, onde todos podem editar seu conteúdo, e em pouco tempo diversos voluntários já haviam se cadastrado, com menos de 3 meses o projeto possuía 1 milhão de novos registros geográficos criados apenas por voluntários. Em julho de 2012 o projeto já atingia a marca de 19 milhões de registros geográficos criados \cite{Wikimapia:history}.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figuras/wikimapia.png}
    \caption{Modo de inserção de dados do portal \textit{wikimapia}.}
    \label{fig:wikimapia}
\end{figure}

Outro projeto que merece destaque nesta categoria é o renomado \textit{OpenStreetMaps} (OSM). Muito parecido com a ferramenta de mapas do Google, mas de forma livre, o OSM possui diferentes características e funcionalidades. Lançado em julho de 2004 e deste então vem atraindo novos voluntários a cada dia, tendo um crescimento constante (Figura \ref{fig:osm_table}). Construído para que voluntários mantenham sempre os dados geográficos atualizados, assim como o \textit{wikimapia}, porém o OSM conta diversas funcionalidades para integração dos seus dados a projetos de terceiros, utilizando-se de protocolos abertos e com muitas opções para exportar os dados. 

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figuras/osm_table3.PNG}
    \caption{Gráfico do crescimento mensal de usuários registrados e contribuições realizadas ao projeto \textit{OpenStreetMap}.}
    \FONTE{\citeonline{haklay2008openstreetmap}}
    \label{fig:osm_table}
\end{figure}

\subsubsection{Sistemas de Alertas}

Estudos sugerem que este novo conceito de explorar e criar informações geográficas pode levar a um novo paradigma de criação de sistemas de alertas. Considerando cada pessoa como um sensor, há cerca de 7 bilhões de sensores no globo \cite{elwood2008volunteered,Goodchild2007,Gouveia2004,Gouveia2008}. Geralmente, no segundo momento após um desastre como os ocasionados por furacões e tsunamis, é difícil de se ter informações sobre os locais que foram afetados. Inúmeras são as razões, seja por falta de eletricidade, um bom campo de visão para se obter imagens de satélite ou ausência equipamentos de comunicação operacionais. Porém a população das áreas afetadas conhece suficientemente bem o local afetado e poderia reportar ou auxiliar atividades como de resgate, através de dispositivos móveis via mensagens, imagens e voz. Em seu trabalho \citeonline{Schade2011} conclui que dados geográficos obtidos por voluntários podem ser complementares aos dados de sensoriamento remoto.

\subsection{Sensoriamento Móvel}
Na era pós-PC, mencionada pela primeira vez por \citeonline{DavidClark2013:bio}, onde os computadores deixaram de ser o principal dispositivo eletrônico, está se tornando realidade. Os computadores pessoais estão sendo substituídos ou utilizados em outras funções, como há décadas muitos já previam. Sua utilidade está mais fadada a de ser um \textit{hub} tecnológico, servindo de meio de comunicação com outros dispositivos móveis como \textit{smartphones} e \textit{tablets}. No início dos anos 90, os celulares eram realidades para poucos, mas diversos fatores influenciaram a sua popularização ao longo do tempo. O avanço da tecnologia permitiu, por exemplo, reduzir o tamanho dos componentes eletrônicos e sensores físicos digitais, também a quantidade de energia requerida por esses. 

Diversos tipos de sensores estão cada vez mais presentes em celulares, tornando dispositivos móveis em unidades de coleta de informação de grande precisão. Câmeras e sensores de localização já são frequentes na maioria dos celulares, permitindo obter a sua localização em qualquer parte do globo terrestre através de \textit{GPS}\footnote{\textbf{G}lobal \textbf{P}ositioning \textbf{S}ystem é um sistema de navegação baseado em uma constelação de 24 satélites.}, sendo alguns modernos integrado com \textit{GLONASS}\footnote{\textbf{GLO}bal \textbf{NA}vigatsionnaya \textbf{S}putnikovaya \textbf{S}istema, um sistema de navegação russo, constituído por uma constelação de 21 satélites}. Há também dispositivos que apresentam sensores de proximidade, giroscópio, magnetômetro, acelerômetro, barômetro e sensor de luz ambiente. Além desses dispositivos, há o microfone que, em conjunto com os demais sensores supracitados, pode ser utilizado como ferramenta de monitoramento ambiental.

Em recentes relatórios, \citeonline{Gartner2014} aponta que em algum momento de 2015 os dispositivos móveis (\textit{tablets}, celulares e \textit{smartphones}) irão ultrapassar os computadores pessoais (computadores de mesa e portáteis), em quantidade, conforme Figura \ref{fig:gartner}.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figuras/gartner2014.png}
    \caption{Relatório Gartner julho/2014}
    \FONTE{\citeonline{Gartner2014}}
    \label{fig:gartner}
\end{figure}

Com esta visão, novos projetos tem surgido com a intenção de utilizar os sensores presentes nos dispositivos móveis como fonte de dados científicos, coletando constantemente informações do dia a dia de quem os utilizam \cite{Lane2010,Burke2006}. 

Por anos a comunidade acadêmica e industrial vem debatendo o uso de dispositivos móveis em pesquisas de sensoriamento, porém sem grandes avanços até datas recentes. \citeonline{Lane2010} atribui esta mudanças aos seguintes fatores:

\begin{enumerate}
    \item Sensores embarcados - utilizados primeiramente como forma de melhorar a experiência de uso para os usuários, como acelerômetros, encontraram novas formas de uso e chamaram a atenção de pesquisadores. Diversos sensores novos estão revolucionando as pesquisas, como GPS e barômetro.
    \item Programabilidade - Há uma coleção infinita de documentação na internet de como programar para dispositivos móveis de terceiros. As grandes plataformas de dispositivo móveis, como iOS (Apple), Android (Google), e Windows Phone (Microsoft) possuem documentações detalhadas, permitindo qualquer pessoa com um pouco de conhecimento de programação aprender a linguagem e desenvolver aplicativos.
    \item Lojas de aplicativo - Os desenvolvedores de aplicativos utilizam o serviço de loja de aplicativo do fabricante correspondente para publicar sua nova criação. Permitindo alcançar diferentes tipos de usuários em toda a parte.
    \item Computação na nuvem - Utilizando-se de computação na nuvem, os dispositivos móveis podem armazenar dados e até efetuar cálculos através de servidores na internet, sem a necessidade de utilizar estas funcionalidades apenas local, proporcionando um grande crescimento de uso e descentralização de dados.
\end{enumerate}

\chapter{ForestWatchers}
\label{ch:forestwatchers}

O projeto ForestWatchers (\url{http://www.forestwatchers.net}) propõe o desenvolvimento e o lançamento de uma iniciativa de ciência cidadã com o objetivo de involver e integrar cidadãos ao redor do planeta na tarefa de monitorar o desmatamento das florestas tropicais \cite{ForestWatchersDesc}. Estes cidadãos poderão de suas casas, por meio de uma interface \textit{Web}, inspecionar imagens recentes de satélite de áreas de florestas. Estas podem ser de uma reserva indígena na Amazônia, uma floresta nacional em Bornéu ou um parque em Queensland. As imagens são então classificadas em áreas de floresta ou não-floresta, por meio de um algoritmo de classificação supervisionado pelos voluntários na \textit{Web}. Conforme mencionado por \citeonline{Ipeirotis2010}, erros e até mesmo fraude podem ser automaticamente tratados pela redundância do sistema. Para isso, é necessário atrair e manter um grande número de voluntários \cite{Soares:2011:EmCiSc}. Estima-se que cem mil voluntários analisando uma área de 100.000 hectares cada, com um fator de redundância de 20, podem examinar uma área de 500 milhões de hectares, cerca de 40\% a 50\% da área estimada das florestas tropicais do mundo \cite{ForestWatchersDesc}.

O projeto conta com desenvolvedores do Laboratório Associado de Computação e Matemática Aplicada (LAC) do INPE, do \textit{Citizen Cyberscience Centre} (CCC), e do Departamento de Ciência e Tecnologia (DCT) da Universidade Federal de São Paulo (UNIFESP), com apoio do \textit{Open Society Foundations} (OSF), \textit{United Nations Institute for Training and Research} (UNITAR), e \textit{UNITAR's Operational Satellite Application Programme} (UNOSAT).

A seguir, será discutida a metodologia empregada no projeto.

\section{Metodologia}
\label{ch:fw_metodologia}

A metodologia usada neste projeto é inspirada no bem-sucedido programa de detecção de desflorestamento DETER do INPE. Assim, como no sistema DETER, o projeto ForestWatchers também utiliza imagens do sensor MODIS, com resolução de $250$ metros (porém qualquer outro sensor de satélite que forneça suas imagens gratuitamente pode ser utilizado). Para que essas imagens possam ser exibidas para os voluntários é necessário que um pré-processamento seja feito. 

Um diagrama ilustrativo da metodologia utilizada pelo projeto ForestWatchers pode ser visto na Figura \ref{fig:estrutura_atual}.
\begin{figure}[htb]
\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figuras/arquitetura_atual.png}
\caption{A metodologia utilizada pelo projeto ForestWatchers.}
\label{fig:estrutura_atual}
\FONTE{\citeonline{ForestWatchersDesc}}
\end{figure}

Primeiramente é necessário adquirir as imagens da NASA referentes à área de interesse do projeto. Para esse processo, ferramentas como FTP\footnote{\textit{File Transfer Protocol (FTP)} é um protocolo para transferência de arquivo utilizado na internet para efetuar \textit{downloads} e \textit{uploads} de arquivos.}e WGET\footnote{WGET é um programa livre para efetuar \textit{download} de conteúdos na internet.} são utilizadas para realizar os downloads necessários. A próxima etapa, envolve recortar as imagens que não são pertinentes à área de interesse, descartando-as e consolidando as imagens restantes num único arquivo GeoTIFF de 16 bits. Essa etapa pode ser executada rapidamente com o auxílio da ferramenta MODIS Reprojection Tool (MRT) \cite{MRToolManual2010}, um software gratuito disponibilizado pela NASA.

As imagens de 16 bits são convertidas para 8 bits por meio de um \textit{script} em Python\footnote{Python é uma linguagem de programação aberta.}. Logo após, uma única imagem é consolidada utilizando-se três bandas (infravermelho médio, vermelho, infravermelho próximo) da imagem de 8 bits. Assim, essa imagem pode ser enviada para um servidor gerenciador de arquivos de mapa. Nesse projeto utiliza-se o MapServer (\url{http://www.mapserver.org}), responsável por tratar as requisições de inserção e seleção das imagens georreferenciadas, e de retornar apenas parte da imagem desejada na forma de \textit{tiles}. Todos os arquivos relacionados à imagem têm suas informações extraídas no formato GeoJSON\footnote{\textit{Geographic JavaScript Object Notation} é um formato para codificar variados tipos de estruturas geográficas.}, para facilitar a comunicação entre os outros módulos. O algoritmo de classificação (ainda em desenvolvimento) faz a segmentação das imagens, classificando-as como  áreas de floresta e de não-floresta. Existindo a necessidade de supervisão das imagens, são criadas tarefas para os usuários poderem classificá-las visualmente.

O \citeonline{PyBossa2013} é o sistema responsável por gerenciar a criação e distribuição das tarefas automaticamente, conforme necessário. Esse é um sistema livre que permite um usuário criar e gerenciar projetos que requeiram cognição humana, tais como classificação de imagem, transcrição e geo-codificação. Esse sistema é baseado no \citeonline{Boinc2008}, plataforma online desenvolvida para facilitar a criação e a operação de projetos baseados em ciência cidadã. Essa nova implementação traz maiores benefícios em relação ao sistema original, BOSSA, por ser desenvolvida em Python e possuir uma API\footnote{\textit{Application Programming Interface} (API) é um protocolo com o objetivo de servir como interface para os componentes de softwares, permitindo comunicarem entre si.} REST \cite{Richardson2008}. 

Com as tarefas criadas, os voluntários podem classificar as imagens de forma ordenada. O projeto, com o uso do sistema de redundância que envia a mesma tarefa para diferentes voluntários, garante um aumento na confiabilidade dos resultados \cite{Ipeirotis2010}.

\chapter{Metodologia}
\label{ch:metodologia}

O conceito de um módulo de sensoriamento voluntário consiste basicamente de \textbf{(a)} um dispositivo capaz de coletar dados, aasociado a uma \textbf{(b)} estrutura de recebimento e armazenamento, e a \textbf{(c)} um sistema de visualização dos dados obtidos \cite{VolunteerSensing2011,Gouveia2008}. 

Para o teste deste conceito o seguinte módulo foi construído em duas etapas. Primeiramente, um aplicativo híbrido, utilizado pelos voluntários para enviarem os dados coletados a partir de um dispositivo móvel, foi desenvolvido. Em seguida, implementou-se uma infraestrutura tecnológica de camadas, divida em camada de recebimento, camada de armazenamento, camada de processamento e camada de visualização dos dados.

Este capítulo descreve a metodologia utilizada em cada etapa da construção do módulo e detalha o experimento de coleta de dados utilizado para teste em condições reais do módulo.

\section{Aplicativos} % (fold)
\label{sub:aplicativos}

Tendo como foco o dispositivo de coleta de dados mais comum e geral possível, de modo a aumentar o abrangência do projeto FW, optou-se por desenvolver uma aplicação para dispositivos móveis do tipo (\textit{smartphones} e \textit{tablet}). Hoje, a grande maioria das pessoas possui um dispositivo móvel com capacidade de conectar-se à internet, tirar fotos, captar áudio e gravar vídeos. Com a popularização dos sensores embarcados em dispositivos móveis e as expectativas de crescimento deste mercado \cite{Lane2010,Gartner2014}, utilizá-los como ferramenta para projetos de ciência cidadã é uma abordagem natural.

Foram criados quatro aplicativos como protótipos para testar suas funcionalidades e verificar a sua significância em relação as necessidades do projeto: (i) um aplicativo utilizando bibliotecas nativas, disponibilizadas pelos fabricantes de dispositivos móveis para criar novos aplicativos, como estes que são facilmente encontrados nas lojas online; (ii)  dois aplicativos baseados sistemas prontos ou de fácil uso para a criação da ferramenta de coleta de dados; e por fim, (iii) um aplicativo utilizando uma abordagem de desenvolvimento de aplicativos híbrido, onde há uma biblioteca em comum entre os demais dispositivos existentes e necessitando de apenas uma linguagem de programação.

Cada fabricante de dispositivos móveis disponibiliza conjuntos de códigos a serem utilizados para desenvolver aplicativos. Estes são conhecidos por biblioteca, \textit{Application Programming Interface} (API) ou \textit{Software Development Kit} (SDK). A maioria dos fabricantes fornecem essas bibliotecas sem custos, porém, para poder publicar um aplicativo nas lojas online, alguns fabricantes requerem uma assinatura anual (Tabela \ref{tab:tabela_custo}).

Estas bibliotecas permitem desenvolver aplicativos para diversos dispositivos do mesmo fabricante. A Microsoft, por exemplo, permite criar aplicativos tanto para seus sistemas \textit{Desktop} (\textit{Windows}) quanto para aplicativos móveis (Windows Phone e \textit{Tablets}). Outros fabricantes já são mais restritivos e requerem a aquisição de uma outra licença para produtos diferentes, como a Apple para \textit{Desktop}, \textit{Smartphone} e \textit{Tablet}.

Na Tabela \ref{tab:tabela_custo}, as plataformas mostradas são referentes a pesquisa realizada por \citeonline{IDC:2014Q3}, onde aparecem somente as plataformas que foram mais consumidas de 2011 a 2014.

\begin{table}[htb]
\caption{Preço de Licença de Desenvolvimento por Plataforma.}
\label{tab:tabela_custo}
\resizebox{\textwidth}{!}{
    \begin{tabular}{@{}llll@{}}
    \toprule
    Plataformas                            & Dispositivos                            & Principal Linguagem & Licença  \\ \midrule
    iOS (Apple)                            & Smartphones, Tablets                    & Objective-C         & \$99/ano \\
    BlackBerry OS (RIM)                    & Smartphones                             & Java                & \$0      \\
    Windows 8, Windows Phone 8 (Microsoft) & Desktop, Smartphones, Tablets           & .NET                & \$19/ano \\
    Android (Google)                       & Acessório, Desktop, Smartphone, Tablets & Java                & \$25/ano \\ \bottomrule    
    \end{tabular}    
}
\FONTE{\citeonline{Registration:Android:2014,Registration:iPhone:2014,Registration:rim:2014,Registration:WP8:2014}}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5

\subsection{Aplicativo de Biblioteca Nativa} % (fold)
\label{ssub:aplicativo_com_biblioteca_nativa}

O primeiro aplicativo desenvolvido como protótipo foi criado para a plataforma Windows Phone da Microsoft dada a disponibilidade de um \textit{smartphone} moderno, o Nokia Lumia 800, lançado no final de 2011\footnote{\url{http://www.gsmarena.com/nokia_lumia_800-4240.php}}. Este aparelho possui sensores de localização (GPS assistido), acelerômetro, bússola, proximidade, câmera de 8 megapixel com georreferenciamento, dentre outros. Um sensor de localização GPS assistido tem a inicialização do seu serviço mais rápido do que um GPS convencional, pois pode utilizar informações de redes \textit{wireless} ou 3G para obter um melhor posicionamento inicial. Acelerômetros permitem monitorar a inclinação do aparelho nos eixos X, Y e Z, fornecendo assim qual a posição do celular ao capturar uma imagem. Câmeras com a habilidade de georreferenciamento permitem incluir informações geográficas no cabeçalho de uma imagem, vídeo ou áudio, assim que estes são capturados. Este cabeçalho pode posteriormente ser lido e compreendido por outros softwares através do padrão \textit{Exchangeable Image File Format} (EXIF) \cite{JEITA2002}.

Um simples aplicativo foi então desenvolvido para capturar uma imagem utilizando a câmera do dispositivo, guardar as coordenadas geográficas através do georreferenciamento e enviá-las a um servidor, extraindo as informações necessárias. Seu esquema de funcionamento é apresentado na Figura \ref{fig:wp7}. 

\begin{figure}[htb]
\centering
\includegraphics[keepaspectratio,width=0.9\textwidth]{figuras/prot_app_01.png}
\caption{Esquematização do protótipo do aplicativo, incluindo uma aplicação cliente, responsável por capturar a imagem e enviá-la ao servidor de através de REST. Os dados GeoJSON são armazenados no banco de dados e a imagem no servidor de imagens. Posteriormente, ao exibir a mesma imagem, a página web faz a requisição da imagem e a requisição dos dados aos respectivos servidores, combinando seus resultados para exibição.}
\label{fig:wp7}
\end{figure}

Ao enviar o único arquivo contendo apenas a imagem capturada para o servidor, todas as informações do cabeçalho do arquivo são extraídas e armazenadas em um banco de dados geográfico, utilizando o formato GeoJSON \footnote{\url{http://geojson.org/}}. A imagem é armazenada em um diretório específico, para que possa ser rapidamente lida e exibida em uma página web. As primeiras imagens capturadas pelo aplicativo para teste do trabalho foram feitas de dentro do INPE em São José dos Campos. Uma página web foi criada para visualizar os resultados deste protótipo e, com esta, um mapa do sistema Bing\footnote{\url{http://www.bing.com/maps/}} foi utilizado para mostrar os imagens captadas sobrepostas como pontos de interesse. Ao clicar no ícone de cada ponto de interesse, a imagem correspondente é exibida com as suas informações de identificação de imagem do banco de dados, coordenada geográfica, altitude, precisão e data de criação. 

Alguns problemas foram detectados no uso deste protótipo, o que inviabilizou o seu uso. Estes são:

\begin{itemize}
    \item \textbf{Precisão Geográfica}. Aparelhos \textit{smartphone}, em geral, não informam o nível de precisão do georreferenciamento utilizado, tornando este aplicativo inviável. Erros de precisão de GPS podem ser na ordem de quilômetros de distância do ponto original; \textit{smartphones} que possuem esta funcionalidade podem não captar uma posição geográfica por alguma falha e o usuário só saberá posteriormente.
    \item \textbf{Georreferenciamento Automatizado}. Assim como não é possível determinar a precisão ou qualidade captada pelo sensor e que será georreferenciada na mídia, tampouco é possível prever que todas as mídias (áudio, vídeo, imagens) de um \textit{smartphone} serão georreferenciadas automaticamente, uma vez que esta funcionalidade difere conforme a plataforma. O dispositivo Lumia 800 possui somente imagens georreferenciadas, por exemplo.
    \item \textbf{Múltiplas Plataformas}. Aplicativos desenvolvidos para uma única plataforma atrairão menos voluntários do que aplicativos desenvolvidos para mais de uma plataforma. Este é o ponto crítico para o desenvolvimento de aplicativos de sensoriamento voluntário.
\end{itemize}

\subsection{Aplicativo de Sistema Pronto} % (fold)
\label{ssub:aplicativo_de_sistema_pronto}

{\centering
\begin{table}[htb]
     \label{tab:tipo_de_dados}
     \small
     \caption{Tipo de Dados Utilizados Pelo EpiCollect e EpiCollect+}
     \begin{center}
         \begin{tabular}{ p{2cm}  p{12cm}  }
             \toprule
              \tiny{Controle} & \tiny{Descrição} \\ 
            \cmidrule(lr){1-1}\cmidrule(l){2-2}
             \raisebox{-0.5\height}{\centering\includegraphics[scale=0.4]{figuras/epicollect/_input_text.png}}
                               &
              \tiny
                      Entrada de texto livre. Utilizado com maior frequência para responder perguntas feitas no formulário.
                                Opções:
                                
                                Rótulo. Exibição do texto como rótulo;
                                Obrigatório. O usuário deve informar este dado;
                                Numérico. Opção para tornar o campo numérico (EpiCollect).
                                
              \\ 

             \raisebox{-0.5\height}{\centering\includegraphics[scale=0.4]{figuras/epicollect/_input_numeric.png}}
              & 
                                \tiny
                                Entrada de número. Para o EpiCollect, um campo de entrada de texto com a opção ``Numérico'' deve ser selecionado para ter a mesma função.
                                Opções:
                                
                                Rótulo. Exibição do texto como rótulo.
                                Obrigatório. O usuário deve informar este dado.
                                Decimal. Permitindo casas decimais.
                                Integer. Permitindo somente entrada de números inteiros.
                                Valor Máximo. Valor máximo permitido para este campo.
                                Valor Mínimo. Valor mínimo permitido para este campo.
                                Padrão. Valor padrão a ser especificado ao preencher o campo.
                                Entrada Dupla. O usuário deve entrar com o dado duas vezes para confirmar o seu valor.
                                
                                \\ 

             \raisebox{-0.5\height}{\centering\includegraphics[scale=0.4]{figuras/epicollect/_input_date.png}}
              & 
                                \tiny
                                Entrada de data. Este dado não possui para a versão do EpiCollect, apenas para o versão EpiCollect+.
                                \\ 

                                \raisebox{-0.5\height}{\centering\includegraphics[scale=0.4]{figuras/epicollect/_input_time.png}}
                                & 
                                \tiny
                                Entrada de Hora. Este dado não possui para a versão do EpiCollect, apenas para o versão EpiCollect+.
                                \\ 

             \raisebox{-0.5\height}{\centering\includegraphics[scale=0.4]{figuras/epicollect/_input_dropdown.png}}
                                &
                                \tiny
                                Entrada de dados por seleção. Este dado não possui para a versão do EpiCollect, apenas para o versão EpiCollect+.
                                Esta entrada permite escolher um valor através de uma lista.
                                Opções:
                                
                                Rótulo. Exibição do texto como rótulo.
                                Obrigatório. O usuário deve informar este dado.
                                
                                \\ 

             \raisebox{-0.5\height}{\centering\includegraphics[scale=0.4]{figuras/epicollect/_input_radio.png}}
                                &
                                \tiny
                                Entrada de dados por seleção. Este dado não possui para a versão do EpiCollect, apenas para o versão EpiCollect+.
                                Esta entrada permite escolher um valor através de uma lista, mostrando todos ao mesmo tempo.
                                Opções:
                                
                                Rótulo. Exibição do texto como rótulo.
                                Obrigatório. O usuário deve informar este dado.
                                
                                \\ 

             \raisebox{-0.5\height}{\centering\includegraphics[scale=0.4]{figuras/epicollect/_input_checkbox.png}}
                                &
                                \tiny
                                Entrada de dados por seleção. Este dado não possui para a versão do EpiCollect, apenas para o versão EpiCollect+.
                                Esta entrada permite escolher múltiplos valores através de uma lista, mostrando todos ao mesmo tempo.
                                Opções:
                                
                                Rótulo. Exibição do texto como rótulo.
                                Obrigatório. O usuário deve informar este dado.
                                
                                \\ 

             \raisebox{-0.5\height}{\centering\includegraphics[scale=0.4]{figuras/epicollect/_input_multiline.png}}
                                &
                                \tiny
                                Entrada de texto.
                                \\ 

             \raisebox{-0.5\height}{\centering\includegraphics[scale=0.4]{figuras/epicollect/_input_location.png}}
                                &
                                \tiny
                                Entrada da coordenada geográfica. Este dado não possui para a versão do EpiCollect, apenas para o versão EpiCollect+.
                                Permite visualizar antes de salvar:
                                
                                A coordenada geográfica atual.
                                A altitude da coordenada atual.
                                A orientação captada pela GPS atua.
                                A precisão utilizada na captação dos dados acima.
                                
                                \\ 

             \raisebox{-0.5\height}{\centering\includegraphics[scale=0.4]{figuras/epicollect/_input_photo.png}}
                                &
                                \tiny
                                Entrada de foto. Este dado não possui para a versão do EpiCollect, apenas para o versão EpiCollect+.
                                Permite captar uma nova foto ou selecionar uma a partir da memória do dispositivo.
                                \\ 

             \raisebox{-0.5\height}{\centering\includegraphics[scale=0.4]{figuras/epicollect/_input_video.png}}
                                &
                                \tiny
                                Entrada de vídeo. Este dado não possui para a versão do EpiCollect, apenas para o versão EpiCollect+.
                                Permite captar uma nova vídeo ou selecionar uma a partir da memória do dispositivo.
                                \\ 

             \raisebox{-0.5\height}{\centering\includegraphics[scale=0.4]{figuras/epicollect/_input_audio.png}}
                                &
                                \tiny
                                Entrada de áudio. Este dado não possui para a versão do EpiCollect, apenas para o versão EpiCollect+.
                                Permite captar uma nova áudio ou selecionar uma a partir da memória do dispositivo.
                                \\ 

             \raisebox{-0.5\height}{\centering\includegraphics[scale=0.4]{figuras/epicollect/_input_barcode.png}}
                                &
                                \tiny 
                                Entrada de código de barra. Este dado não possui para a versão do EpiCollect, apenas para o versão EpiCollect+.
                                Permite decodificar um código de barra ou código QR.
                                \\ 

            \bottomrule
          \end{tabular}
      \end{center}
\end{table}
}

Com os problemas relatados anteriormente, buscou-se uma nova solução. Há diversos aplicativos que são desenvolvidos para uma determinada plataforma e posteriormente são migrados para uma outra plataforma, tornando-os multiplataforma. Com essa característica alguns aplicativos tornam-se poderosas ferramentas de coleta de dados, inclusive adicionando as informações de alguns dos sensores presentes no dispositivo. Algumas destas ferramentas utilizam formulários para guiar a coleta de dados, construídos através de interfaces gráficas de fácil manipulação. Estes sistemas prontos são indicados para efetuar a criação aplicativos voltado para pesquisas ou coleta de dados de uma forma rápida, uma vez que possuem toda uma infraestrutura para armazenamento de dados e sua visualização.

EpiCollect+ é a segunda geração de um conhecido sistema pronto. Esta nova versão possui diversos novos recursos \cite{Aanensen2009:epicollect}, como captura de  imagens, vídeos, áudios, localização geográfica e leitura de código de barra. Este sistema é de fácil uso, bastando ter acesso à internet para que o usuário possa criar de um novo projeto, especificar a sua visibilidade (público ou privado), definir se este poderá aparecer na página da internet e criar um formulário (Figura \ref{fig:epicollect_formulario}).  

\begin{figure}[htb]
\centering
\includegraphics[keepaspectratio,width=0.7\textwidth]{figuras/epicollect/03_FORM_ANTIGO.png}
\caption{Um formulário criado para o EpiCollect+, com a finalidade de capturar uma imagem, foto ou vídeo, com a data e hora de aquisição, a coordenada geográfica e algum comentário adicional. }
\label{fig:epicollect_formulario}
\end{figure}

Esta segunda geração do aplicativo possui mais tipos de dados do que o primeiro, conforme observado na Tabela \ref{tab:tipo_de_dados}.

Um simples formulário foi criado (Figura \ref{fig:epicollect_formulario}) para verificar a viabilidade do sistema. Os dados do formulário são interpretados pelo PyBossa na fase de avaliação Figura \ref{fig:pybossa_pertinente}, onde voluntários classificam as diversas imagens como pertinentes ao projeto (caso seja uma imagem de floresta, área sem floresta, etc.) ou não. Esta simples pergunta pode determinar o nível de comprometimento que um voluntário tem com o projeto, determinando se as imagens que este submete podem ser levadas em consideração ou não.

\begin{figure}[htb]
\centering
\includegraphics[keepaspectratio,width=0.7\textwidth]{figuras/_pertinencia.png}
\caption{Fase de avaliação utilizando o sistema PyBossa para verificar a pertinência da imagem em relação ao projeto.}
\label{fig:pybossa_pertinente}
\end{figure}

Uma vez que todos os dados foram capturados e os formulários corretamente preenchidos, estes são salvos e o voluntário pode inserir um novo registro ou efetuar a sincronização com o servidor do EpiCollect+. A sincronização pode também ser feita posteriormente, a critério do voluntário, mantendo os dados de forma \textit{offline}.

O administrador do projeto pode verificar os dados online (Figura \ref{fig:epicollect_dados_online}) e usá-los localmente após baixar os arquivos em csv\footnote{\textit{Comma-separted values} (csv) é um formato de arquivo cujos dados são separados por meio de vírgulas.}, tsv\footnote{\textit{Tab-separted values} (tsv) é um formato de arquivo em que seus dados são separados por meio tabulações.} ou xml\footnote{\textit{eXtensible Markup Language} (XML), um tipo de linguagem de marcação.}, dependendo da necessidade.

\begin{figure}[htb]
\centering
\includegraphics[keepaspectratio,width=0.7\textwidth]{figuras/epicollect/05_ALL_EPICOLLECT_DATA.png}
\caption{Os dados são mantidos nos servidores do EpiCollect+ para uso do administrador do projeto. }
\label{fig:epicollect_dados_online}
\end{figure}

Apesar de apresentar melhores soluções para coletar diferentes tipos de dados, o EpiCollect+ possui apenas aplicativos para a plataforma Android. Assim como EpiCollect+, o Sensr tem a mesma função de criar formulários online e através do seu aplicativo utilizá-los como ferramenta de pesquisa. Porém, assim como EpiCollect+, trabalha com uma única plataforma, o iOS.

\subsection{Aplicativo de Biblioteca Híbrida} % (fold)
\label{ssub:aplicativo_com_biblioteca_hibrida}

Em 1991 o primeiro sítio eletrônico foi criado, feito realizado por Berners-Lee em 1991 \cite{berners1992world}. Estima-se que em setembro de 2014 o número de sítios existentes chegou a marca de 1 bilhão \cite{InternetLiveStats:2015}. 

Os sítios evoluíram, deixaram de ser simples páginas estáticas e passaram a ser mais dinâmicos. Hoje permitem que diversos usuários interajam ao mesmo tempo, efetuem pagamentos, realizem pesquisas e atualizem conteúdo de forma simples. Estas novas funcionalidades só foram alcançadas através de grandes evoluções das tecnologias empregadas no começo da \textit{World Wide Web}. Existem diversas tecnologias de servidores para exibir um sítio com conteúdo dinâmico, como PHP, .NET, Python, etc. HTML e CSS são as duas principais tecnologias para a construção de uma página. O HTML define a estrutura da página e permite o uso de fotos, formulários, links, vídeos, áudios, tabelas, etc. O CSS descreve o layout da página com cores, posições e fontes. Uma página também pode utilizar \textit{scripts} (o mais conhecido, JavaScript) de forma a torná-la mais expressiva, dando dinamicidade ao seu conteúdo, com validações e, até mesmo, carregamento de conteúdo dinâmico. 

HTML, CSS e JavaScript são conhecidos por serem os pilares para uma página moderna. Estes são padronizados pela \textit{World Wide Web Consortium} (W3C). Criado por Berners-Lee em 1994, este consórcio é constituído por quase 400 membros, como empresas, órgãos governamentais e organizações independentes, todos com a finalidade de estabelecer padrões para a criação e a interpretação de conteúdos para a Web. Sem a existência destes padrões, haveria diversos navegadores para a internet, cada um interpretando uma determinada página de forma diferente do outro, tendo o usuário que trocar de navegador a cada nova navegação.

O desenvolvimento de aplicativos utilizando bibliotecas nativas são mais comuns, por poderem usufruir de todas as funcionalidades oferecidas pelos fabricantes de dispositivos móveis e também por serem mais rápidos \cite{Charland:2011:Mobile}. Entretanto esta forma de desenvolvimento de aplicativos pode não ser vantajosa para um desenvolvedor que busca alcançar o máximo de pessoas possível. Neste caso é melhor que o aplicativo seja desenvolvido de todas as plataformas possíveis (ver Figura \ref{fig:developerforce}). 

\begin{figure}[ht]
\begin{center}
\includegraphics[keepaspectratio,width=0.7\textwidth]{figuras/developerforce_chart.png} %8.5
\end{center}
\caption{Aplicativos móveis podem ser desenvolvidos de três formas: com biblioteca Nativa (plataforma única); HTML5 (multiplataforma e capacidade parcial); e Híbrida (multiplataforma e capacidade total).}
\FONTE{\citeonline{Korf2013}}
\label{fig:developerforce}
\end{figure}

Todas as plataformas permitem que um desenvolvedor instancie um navegador dentro da sua aplicação de forma que este passe a se comportar como uma nova tela nativa da aplicação. Estas ainda permitem a interação de códigos nativos através da utilização de JavaScript. Esta técnica foi utilizada pela primeira vez por Eric Oesterle, Rob Ellis, e Brock Whitten para a plataforma iOS, depois sendo portado para outras plataformas \cite{Charland:2011:Mobile}. O \textit{framework} de código aberto para o desenvolvimento de aplicativos híbridos conhecido por PhoneGap foi fruto desta técnica. Em 2011 a empresa Adobe\footnote{\url{http://www.adobe.com}} adquiriu a criadora deste \textit{framework}, Nitobi, mantendo-o como código aberto \cite{Adobe:Nitobi:2011}. O PhoneGap foi então doado para a Fundação de Software Apache sob o nome de Apache Cordova\footnote{\url{http://cordova.io/}}. O propósito desta mudança foi o de manter o código sempre aberto e em constante desenvolvimento \cite{PhoneGap:FAQ:2015}.

A relação de PhoneGap e Cordova pode parecer confusa, porém a Adobe esclarece que o PhoneGap é apenas uma distribuição livre do cordova, geralmente logo na versão mais atualizada deste último \cite{PhoneGap:FAQ:2015}.

Na sua versão mais atual, PhoneGap 4.0.0, existem mais de nove plataformas suportadas\footnote{\url{http://cordova.apache.org/contribute}}. Algumas das principais podem ser vistas na Figura \ref{fig:phonegap_platforms}. Entre estas estão as plataformas citadas na Tabela \ref{tab:tabela_custo}. As principais funcionalidades encontradas nas bibliotecas nativas estão também presentes no PhoneGap (ver Fig. \ref{fig:phonegap_platforms}). A partir da versão 3.0 e superior, o PhoneGap oferece estas funcionalidades através de plugins que podem ser obtidos na página do projeto Cordova. 

\begin{figure}[ht]
\begin{center}
\includegraphics[keepaspectratio,width=0.7\textwidth]{figuras/phonegap_platforms.png}
\end{center}
\caption{Plataformas e funcionalidades suportadas pela versão 4.0.0 do PhoneGap. As funcionalidades com um asterisco são suportadas através de \textit{plugins} de terceiros \cite{PhoneGap:PlatformSupport:2015}.}
\label{fig:phonegap_platforms}
\end{figure}

Estes plugins permitem que apenas as funcionalidades desejadas sejam integradas ao aplicativo. Desta forma é possível manter o desenvolvimento de uma aplicação modular, tendo diversos plugins em diversas aplicações cada qual com diferentes versões. Portanto, não há mais a necessidade de atualizar todo o conjunto, apenas atualizar o plugin necessário e para a versão necessária. 

Um plugin refere-se a uma funcionalidade específica do dispositivo a ser encapsulado por um código Javascript para sua utilização pelo framework PhoneGap. Em termos de Programação Orientada a Objetos, a biblioteca Javascript deste framework tem a funcionalidade de uma interface, na qual são definidas as chamadas aos métodos que serão utilizados. A implementação destas funcionalidades é feita a nível de plataforma, de modo a obter a funcionalidade desejada pela interface que a invocou, Figura \ref{fig:phonegap_layers}.

\begin{figure}[htb]
\begin{center}
\includegraphics[scale=0.8]{figuras/layers.png}
\end{center}
\caption{A partir da versão 3.0, o framework PhoneGap vem utilizando plugins para adicionar diversas funcionalidades aos aplicativos. A camada de visualização é composta por HTML5 e CSS, enquanto a camada lógica é composta pelo Javascript do framework \cite{PhoneGap:CommandLine:2015}.}
\label{fig:phonegap_layers}
\end{figure}

Diversos novos plugins podem ser desenvolvidos cobrindo novas funcionalidades, novos sensores e para novas plataformas. O PhoneGap mantém 19 plugins para as funcionalidades de bateria, câmera e áudio, GPS e sensores de movimento, conexão, contatos, dispositivo, arquivos e armazenamento, notificação e transferência de arquivos (ver Fig. \ref{fig:phonegap_platforms}) . Porém, na página oficial\footnote{\url{http://plugins.cordova.io}}, podem ser encontrados outros 678 diferentes plugins, alguns executando funcionalidades semelhantes e outros ampliando as plataformas suportadas.

Existem duas frentes para se desenvolver com o PhoneGap. A primeira é através do uso de ambientes de desenvolvimento proprietários (Android Studio, Visual Studio, XCode, etc), onde um projeto PhoneGap para determinada plataforma é carregado e onde todo o desenvolvimento é realizado.

A segunda frente de desenvolvimento é através de linhas de comando. Após a instalação do framework PhoneGap, este permite compilar para mais de uma aplicação simultaneamente utilizando apenas linhas de comando. Assim, um desenvolvedor que possui as ferramentas de desenvolvimento para iOS e Android, por exemplo, pode compilar seu aplicativo para ambos apenas através de simples instruções digitados no terminal. 

Como um aplicativo PhoneGap possui plugins e utiliza o JavaScript de interface para acessar suas funcionalidades, o desenvolvedor precisa manter apenas o HTML5, CSS e JavaScript uma única vez. Estes serão replicados para as outras plataformas conforme solicitado através de linha de comando.

Com uma funcionalidade extra, PhoneGap Build\footnote{\url{http://build.phonegap.com}}, o PhoneGap permite que seus usuários compilem seus aplicativos para mais de uma plataforma pela internet. Utilizando linhas de comando ou através de um arquivo zip que contenha os arquivos HTML, CSS e JavaScript necessários, o PhoneGap Build disponibiliza rapidamente um novo aplicativo compilado. Este ainda permite incluir a chave de acesso de desenvolvedor das demais plataformas, gerando assim um aplicativo pronto para inserir nas lojas de aplicativos existentes.

Para o projeto FW foi criado um aplicativo híbrido com o framework PhoneGap. Este aplicativo utilizou jQueryMobile (jQM)\footnote{\url{http://jquerymobile.com/}} para construir a interface gráfica. jQM é um framework baseado em HTML5, CSS e JavaScript para construir interfaces gráficas para dispositivos móveis. Junto com este \textit{framework}, utilizou-se a biblioteca KnockoutJS\footnote{\url{http://knockoutjs.com/}}, um \textit{framework} baseado em JavaScript para o uso de padrões de projeto do tipo \textit{Model-View-ViewModel} (MVVM).

A Figura \ref{fig:UMLApplicationUseCase} ilustra o caso de uso do protótipo desenvolvido, onde o voluntário é um dos atores dos casos de uso. O voluntário pode capturar imagem, áudio e vídeo, que são recursos do sistema. Após capturar um recurso, automaticamente é solicitado ao voluntário selecionar um dos dados retornados de GPS e orientação (caso exista bússola no dispositivo).

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{figuras/UML/UMLApplicationUseCase.png}
\caption{Caso de uso do aplicativo desenvolvido para o projeto. O ator deste caso de uso, o voluntário, pode capturar áudios, vídeos e imagens. Em conjunto com estes dados, podem ser capturados ainda a posição geográfica e a sua orientação.}
\label{fig:UMLApplicationUseCase}
\end{figure}

O aplicativo, com o fluxo apresentado na Figura \ref{fig:app_phonegap}, é capaz de capturar imagem, vídeo e áudio, dados dos sensores de localização (GPS) e orientação (bússola). Este aplicativo foi desenvolvido para permitir que no momento da captura dos dados de localização e orientação, o usuário pudesse verificar o nível de precisão dos dados coletados e, se necessário, captar novamente.

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{figuras/dev_app04.png}
\caption{O aplicativo desenvolvido para este projeto baseado em Phonegap. A figura ilustra o fluxograma da captura de uma imagem, adquirindo informações extras do sensor de localização (GPS) e do sensor de orientação (bússola magnética).}
\label{fig:app_phonegap}
\end{figure}

A Figura \ref{fig:UMLApplicationCaptureImageSequence} ilustra a sequência de ações feitas para capturar uma imagem utilizando o aplicativo criado.

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{figuras/UML/UMLApplicationCaptureImageSequence.png}
\caption{Diagrama de sequência ao utilizar o programa para capturar uma imagem, áudio ou vídeo.}
\label{fig:UMLApplicationCaptureImageSequence}
\end{figure}

Os dados captados por este aplicativo são em geral dados dos sensores de localização (GPS), orientação (bússola), informações do dispositivo e informações do arquivo capturado. Estes dados podem ser verificados na Tabela \ref{tab:dados_captados}, onde as principais propriedades são listadas. Dados sobre a configuração de cada sensor também são armazenados, mas apenas para referência. Diversos outros dados poderiam ser captados, mas para um primeiro protótipo apenas estes foram utilizados.

\begin{table}[h]
\centering
\small
\caption{Sumário dos Dados Gravados pelo Aplicativo}
\label{tab:dados_captados}
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Contexto}    & \textbf{Propriedade} & \textbf{Descrição}                         \\ \midrule
\textbf{}            &                      &                                            \\
\textbf{Entrada}     & Nome do Arquivo      & Nome do arquivo gerado                     \\
\textbf{}            & Caminho do Arquivo   & Local do armazenamento do arquivo          \\
\textbf{}            &                      &                                            \\
\textbf{Bússola}     & Norte Verdadeiro     & Valor captado do Norte Verdadeiro          \\
\textbf{}            & Norte Magnético      & Valor captado do Norte Magnético           \\
\textbf{}            & Posição              & Uma posição, seguindo a rosas do vento     \\
\textbf{}            & Seleção Manual       & Posição selecionada por sensor ou manual   \\
\textbf{}            & Precisão             & Valor da precisão captada                  \\
\textbf{}            &                      &                                            \\
\textbf{GPS}         & Latitude             & Posição geográfica da paralela horizontal  \\
\textbf{}            & Longitude            & Posição geográfica da paralela horizontal  \\
\textbf{}            & Precisão             & Valor da precisão captada                  \\
\textbf{}            & Altura               & Altura registrada pelo sensor              \\
\textbf{}            & Precisão da Altura   & Valor da precisão da altura quando captada \\
\textbf{}            & Direção              & Direção sugerida pelo sensor               \\
\textbf{}            & Velocidade           & Velocidade sugerida pelo sensor            \\
\textbf{}            &                      &                                            \\
\textbf{Dispositivo} & UUID                 & Número de identificação único              \\
\textbf{}            & Versão               & Versão do sistema operacional              \\
\textbf{}            & Cordova              & Versão do cordova                          \\
\textbf{}            & Plataforma           & Plataforma utilizada                       \\
\textbf{}            & Modelo               & Modelo utilizado                           \\ \bottomrule
\end{tabular}
}
\end{table}

A sincronização dos dados entre dispositivo e servidor não precisa ocorrer ao mesmo tempo em que as entradas são captadas já que muitas vezes quem irá utilizar o aplicativo estará em lugares remotos. Neste caso, as informações captadas são mantidas apenas no dispositivo para uma sincronização futura e de preferência através de WiFi, uma vez que arquivos de vídeos podem ser bem maiores do que uma foto. 

O conjunto de entradas é armazenado no dispositivo através do plugin de armazenamento interno, que permite persistir objetos no formato JSON. Estes dados permanecerão no dispositivo até que o usuário escolha a opção de remover as entradas, caso este já tenha sincronizado os dados com o servidor. A estrutura de uma única entrada é exibida no Código \ref{json:estrutura_imagem}. 
{\scriptsize
\begin{lstlisting}[language=json,firstnumber=1,float,floatplacement=h, caption={Estrutura JSON para envio de um arquivo de imagem.}, label={json:estrutura_imagem},captionpos=b]
{
  "entry": {
      "picture": {
      "filename" : "",
      "filepath" :  ""
    },
    "compass": {
      "magneticHeading": "",
      "trueHeading": "",
      "orientation": "",
      "useManual": "",
      "accuracy" : "",
    },
    "gps": {
      "latitude": "",
      "longitude": "",
      "accuracy": "",
      "altitude": "",
      "altitudeAccuracy": "",
      "heading": "",
      "speed": ""
    },
    "options": {
      "gpsOptions": {
        "enableHighAccuracy": "",
        "maximumAge": "",
        "timeout": ""
      },
      "compassOptions": {
        "frequency": "",
        "enabled": ""
      },
      "pictureOptions": {
        "quality": ""
      }
    }
  },
  "device": {
    "uuid": "",
    "version": "",
    "cordova": "",
    "platform": "",
    "model": ""
  }
}
\end{lstlisting}
}


\section{Infraestrutura Tecnológica} % (fold)
\label{sub:infraestrutura_tecnologica}

A infraestrutura para receber, armazenar e exibir os dados coletados pelos voluntários baseou-se em tecnologias de código aberto. A finalidade é obter-se uma plataforma de distribuição livre juntamente com seu código fonte, podendo ser enriquecido por outros trabalhos.

A Figura \ref{fig:ArquiteturaServidores} ilustra a infraestrutura que foi criada para atender as necessidades deste módulo.

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{figuras/UML/ArquiteturaServidores.png}
\caption{A arquitetura desenvolvida para o projeto, envolve um servidor de páginas web, um módulo web para receber os dados enviados pelos voluntários, um servidor de mapas responsável por informar dados geográficos e um banco de dados para armazenar dados espaciais.}
\label{fig:ArquiteturaServidores}
\end{figure}

\subsection{Servidor para Internet} % (fold)
\label{sub:servidor_web}

Duas são as principais tecnologias por trás deste projeto. A primeira, o aplicativo para dispositivos móveis, é responsável por coletar os dados dos voluntários; a segunda, o servidor para internet, recebe os dados coletados pelos voluntários, armazena-os adequadamente e exibe-os quando solicitado.

Para a construção da aplicação web, foi utilizado um \textit{framework} criado em Python para construir páginas, aplicações e serviços para a internet, Flask\footnote{\url{http://flask.pocoo.org/}}. Este \textit{framework} permite a construção de soluções para internet de forma rápida por possuir um grande repositório de extensões.

Utilizando Flask foi possível desenvolver um servidor \textit{back-end} responsável por receber os dados enviados pelos voluntários e ao mesmo tempo um servidor \textit{front-end} responsável por mostrar os dados recebidos no formato de uma página web, a interface da plataforma.

\subsubsection{Back-End} % (fold)
\label{ssub:back_end}

O principal meio de comunicação com servidores web é através do protocolo \textit{Hypertext Transfer Protocol} (HTTP), em português Protocolo de Transferência de Hipertexto. Este funciona por meio de requisição e resposta, como cliente e servidor. Um usuário que deseja visualizar uma página da internet faz uma requisição ao servidor para obter o conteúdo desejado, de forma automática através do navegador. 

Uma página, definida pelo endereço \url{http://www.inpe.br/pos_graduacao/cursos/cap/index.php}, é um recurso do servidor \url{www.inpe.br}. Para obter este recurso é necessário efetuar uma requisição (Código \ref{http:inpe_request}) junto ao servidor. Uma vez que encontrado este recurso, uma resposta (Código \ref{http:inpe_response}) é retornada, com informações em seu cabeçalho e, eventualmente, um corpo de resposta. Por este recurso ser uma página web, o \textit{Content-Type} é do tipo text/html. Com essa informação o navegador pode renderizar a página de forma adequada.

\begin{lstlisting}[language=json,firstnumber=1,float, floatplacement=h, caption={Requisição HTTP.}, label={http:inpe_request},captionpos=b]
GET /pos_graduacao/cursos/cap/index.php HTTP/1.1
Host: www.inpe.br
Accept: text/html,application/xhtml+xml
Accept-Encoding: gzip, deflate, sdch
Accept-Language: en-US,en;q=0.8,pt-BR;q=0.6,pt;q=0.4
\end{lstlisting}

% float,floatplacement=H, 
\begin{lstlisting}[language=json,firstnumber=1, float, floatplacement=h, caption={Resposta HTTP.}, label={http:inpe_response},captionpos=b]
HTTP/1.1 200 OK
Server: Apache/2.2.3 (CentOS)
X-Powered-By: PHP/5.1.6
Content-Type: text/html; charset=iso-8859-1
\end{lstlisting}

Este é o princípio do serviço web conhecido por \textit{Representational State Transfer} (REST), em português Transferência de Estado Representacional. Trata-se de serviço do tipo arquitetural baseado no protocolo HTTP projetado para utilizar um conjunto de operações bem definidas, utilizando os principais métodos HTTP (Tabela \ref{tab:metodos_http}), um protocolo cliente-servidor sem estado, um Identificador Uniforme de Recursos (Uniform Resource Identifier - URI) para um determinado objeto e transferência de dados, e podendo utilizar o formato JSON.

\begin{table}[h]
\centering
\small
\caption{Métodos Padrões do Protocolo HTTP}
\label{tab:metodos_http}
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}lll@{}}
\toprule
Método HTTP & Descrição da Ação                                                             & Exemplo de Função                                                                                                             \\ \midrule
GET         & \begin{tabular}[t]{@{}l@{}}Obter informações \\ sobre um recurso\end{tabular} & \begin{tabular}[t]{@{}l@{}}http://servidor.com/imagens\\ (listar todas as imagens)\end{tabular}                                \\
GET         & \begin{tabular}[t]{@{}l@{}}Obter informações \\ sobre um recurso\end{tabular} & \begin{tabular}[t]{@{}l@{}}http://servidor.com/imagem/10\\ (listar a imagem de \\ identificação \#10)\end{tabular}             \\
POST        & Criar um novo recurso                                                         & \begin{tabular}[t]{@{}l@{}}http://servidor.com/imagens\\ (criar um novo objeto imagem)\end{tabular}                            \\
PUT         & Atualizar um recurso                                                          & \begin{tabular}[t]{@{}l@{}}http://servidor.com/imagem/10\\ (atualizar os dados da imagem\\ de identificação \#10)\end{tabular} \\
DELETE      & Remover um recurso                                                            & \begin{tabular}[t]{@{}l@{}}http://servidor.com/imagem/10\\ (remover o objeto imagem \\ de identificação \#10)\end{tabular}     \\ \bottomrule
\end{tabular}
}
\end{table}

As operações que cada método HTTP executa utilizando REST são equivalentes as operações de um banco de dados, como selecionar, inserir, atualizar e remover.

O método \textit{GET} tem a responsabilidade de retornar os recursos solicitados e pode ser utilizando tanto de forma geral, solicitando diversos recursos de uma só vez (em geral, este URI encontra-se no plural) ou de forma específica, informando uma identificação única do recurso. Ao invocar o método \textit{POST} e informando detalhes do objeto, um novo recurso é criado com essas informações (em geral, este URI encontra-se no plural). Os métodos \textit{PUT} e \textit{DELETE} exercem a função de atualizar os dados e removê-los, respectivamente. No primeiro, os dados são informados no corpo da requisição, forma semelhante ao método \textit{POST}. Uma descrição dos métodos pode ser vista na Tabela \ref{tab:metodos_http}.

REST é apenas um estilo arquitetural para receber ou enviar dados. Assim, tem-se que o meio de comunicação com o servidor deste projeto é dado através do protocolo HTTP, mesmo protocolo utilizado para requisições de páginas da internet. Porém, para armazenar os dados, ainda é necessário ter um banco de dados. 

Como a principal característica deste projeto é permitir georreferenciar dados coletados \textit{in-situ}, um banco geográfico é requerido. Optou-se por utilizar o banco de dados de código aberto PostgreSQL\footnote{\url{http://www.postgresql.org/}}. Este banco de dados oferece meios para adicionar entidades geográficas através da extensão PostGIS\footnote{\url{http://postgis.org/}}. Bancos geográficos possuem funções especiais para tratar este tipo de entidade, permitindo efetuar buscas tendo como parâmetro uma posição geográfica.

Cada propriedade, demonstrada no Código \ref{json:estrutura_imagem}, que é capturada pelo voluntário utilizando o aplicativo híbrido descrito na Seção \ref{ssub:aplicativo_com_biblioteca_hibrida}, foi devidamente mapeada no banco de dados, como visto na Figura \ref{fig:moduledb}.

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{figuras/moduledb.png}
\caption{Disposição das tabelas de banco de dados utilizada neste módulo.}
\label{fig:moduledb}
\end{figure}

Assim, o serviço web desenvolvido utilizando Flask permite usar os principais métodos do protocolo HTTP, através do estilo arquitetural REST, para tratar as solicitações dos dados, conforme Tabela \ref{tab:rest_prototipo}.

\begin{table}[h]
\centering
\caption{Configuração do Servidor REST do Projeto.}
\small
\label{tab:rest_prototipo}
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}lll@{}}
\toprule
Método HTTP & Descrição da Ação                                                                       & Recurso                                                                                                                                                              \\ \midrule
GET         & \begin{tabular}[t]{@{}l@{}}Obter informações sobre\\ um ou vários recursos\end{tabular} & \begin{tabular}[t]{@{}l@{}}/api/\{recursos\}\\ (onde \{recursos\} pode ser \\ 'pictures', 'videos' ou 'audios')\end{tabular}                                         \\
GET         & \begin{tabular}[t]{@{}l@{}}Obter informações sobre\\ um ou vários recursos\end{tabular} & \begin{tabular}[t]{@{}l@{}}/api/\{recurso\}/\#id\\ (onde \{recurso\} pode ser \\ 'picture', 'video' ou 'audio'\\ e \#id é a identificação do\\ recurso)\end{tabular} \\
PUT         & \begin{tabular}[t]{@{}l@{}}Atualizar informações\\  de um recurso\end{tabular}          & \begin{tabular}[t]{@{}l@{}}/api/\{recurso\}/\#id\\ (onde \{recurso\} pode ser \\ 'picture', 'video' ou 'audio'\\ e \#id é a identificação do\\ recurso)\end{tabular} \\
DELETE      & \begin{tabular}[t]{@{}l@{}}Remover a informação\\  de um recurso\end{tabular}           & \begin{tabular}[t]{@{}l@{}}/api/\{recurso\}/\#id\\ (onde \{recurso\} pode ser \\ 'picture', 'video' ou 'audio'\\ e \#id é a identificação do\\ recurso)\end{tabular}
\end{tabular}
}
\end{table}

Um serviço web REST permite envio de arquivos para o servidor de três formas:
\begin{enumerate}
    \item Utilização de Base64, onde o arquivo é codificado para uma string de 64 caracteres para ser enviado na requisição.
    \item \textit{multipart/form-data} e \textit{metadata}. Utilizar um formulário, \textit{FormData}\footnote{\url{https://developer.mozilla.org/en-US/docs/Web/Guide/Using_FormData_Objects}}, para enviar apenas os arquivos necessários e aguardar o retorno URI deste arquivo gerado e utilizar o método \textit{PUT} para atualizar as informações deste.
    \item \textit{metatada} e \textit{multipart/form-data}. Método semelhante ao mencionado acima, porém primeiro é enviado as informações do arquivo e um URI é aguardado, uma veste este retornado o arquivo é encaminhado com a identificação do URI.
\end{enumerate}

Apesar destas 3 formas estarem corretas tratando-se de uma arquitetura REST, elas apresentam algumas desvantagens. A primeira aumenta o tamanho do arquivo a ser trafegado pela rede, aumento que pode chegar a mais 33\% do tamanho original. A segunda e terceira esperam um retorno do servidor para continuar o envio, o que eleva a quantidade de transferências necessárias.

Assim, optou-se que enviar um arquivo pelo método tradicional, no contexto web, através de \textit{FormData}, onde arquivos e uma estrutura de chave e valores são informados. Esta estrutura de chave e valores tem que ser padronizada para que o servidor web que recebe a requisição possa saber quais as chaves estão sendo enviadas e quais são necessárias. Os valores de cada chave são os objetos JSON propriamente codificados. 

Portanto, uma vez que uma requisição de envio de imagens foi feita ao servidor do projeto, espera-se um formulário \textit{multipart/form-data} com o arquivo utilizando \textit{FormData} e as informações através de chave e valores de um formulário padrão\footnote{\url{https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest/Using_XMLHttpRequest\#Submitting_forms_and_uploading_files}}.

\subsubsection{Front-End} % (fold)
\label{ssub:front_end}

Para este projeto, uma página web foi desenvolvida para que os dados captados pelos voluntários utilizando o aplicativo híbrido pudessem ser visualizados. Esta página tem que cumprir alguns requisitos para melhor exibir os dados, a saber:

\begin{itemize}
    \item Visualizar de forma rápida todos os dados disponíveis;
    \item Visualizar as propriedades de um dado selecionado;
    \item Exibir o conteúdo de um dado selecionado (imagem, áudio ou vídeo);
    \item Exibir os dados georreferenciados utilizando mapas ou imagens de satélite;
    \item Identificar os diferentes tipos de dados no mapa;
    \item Permitir que o usuário alterne o mapa em exibição;
\end{itemize}

Assim, após alguns protótipos da interface da aplicações web, foi desenvolvida uma página web conforme ilustrado na Figura \ref{fig:frontend_mocqup}, que traz algumas das principais funcionalidades enumeradas abaixo:

\begin{enumerate}[label=\arabic*.]
    \item \textbf{Barra de Navegação.} Reunindo as principais ligações externas do sítio, a barra de navegação é uma importante ferramenta para os sistemas web. O usuário pode utilizar esta para conhecer outros recursos que o sítio pode apresentar. Diversos tipos de recursos podem ser adicionados  a este componente, como menus, seletores, pesquisa e até formulários. A barra de navegação em questão deve permanecer sempre acima do mapa, para que os usuários possam navegar para outros links. 
    
    \item \textbf{Mapa.} Um requisito de uma aplicação web que utiliza dados georreferenciado é poder exibi-los em um mapa. O usuário pode utilizar o mapa para localizar-se melhor.
    
    \item \textbf{Seletor de Camadas.} Uma grande vantagem das aplicações web com mapas é a possibilidade de exibir diversas camadas em uma única aplicação. Pode ser exibida uma camada, aplicar transparência nesta e exibir outras diversas camadas deste modo, formando assim um grande mosaico de imagens georreferenciadas. Este também poderá permitir a alteração da visibilidade dos dados captados, por exemplo, escondendo a camada de fotos, mas manter a de vídeo e áudio visíveis.
    
    \item \textbf{Áudio.} Representação de um dado de áudio que ao apertar um botão, este invoca uma janela modal mostrando todas as suas propriedades.
    \begin{enumerate}[label=4\alph*.]
        \item A miniatura de uma imagem representando um arquivo de áudio na navegação que ao apertar um botão, este invoca uma janela modal mostrando todas as suas propriedades.
    \end{enumerate}
    
    \item \textbf{Foto.} Representação de um dado de foto que ao apertar um botão, este invoca uma janela modal mostrando todas as suas propriedades.
    \begin{enumerate}[label=5\alph*.]
        \item A miniatura de uma imagem representando um arquivo de foto na navegação que ao apertar um botão, este invoca uma janela modal mostrando todas as suas propriedades.
    \end{enumerate}
    
    \item Uma miniatura de imagem representando um arquivo de áudio na navegação que ao apertar um botão, este invoca uma janela modal mostrando todas as suas propriedades.
    \begin{enumerate}[label=6\alph*.]
        \item Vídeo em navegação.
        \item Janela de Propriedades do vídeo. O mesmo para outros tipos de mídia.
        \item Exibição do conteúdo do vídeo. O mesmo para outros tipos de mídia.
        \item Propriedades do vídeo. O mesmo para outros tipos de mídia.
    \end{enumerate}

    \item Navegação. Utiliza miniaturas de imagens para facilitar a navegação do voluntário a procurar uma determinada imagem. Cada vez que uma dessas miniaturas é selecionada, o seu ponto de referência no mapa é destacado e uma janela com suas propriedades pode ser visualizada.
\end{enumerate}

\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{figuras/frontend_mocqup.png}
\caption{Esboço da página de visualização dos resultados, destacando as principais funções conforme descrito acima.}
\label{fig:frontend_mocqup}
\end{figure}

Para o desenvolvimento desta página foi utilizado os \textit{frameworks} Twitter Bootstrap, OpenLayers 2, jQuery e Sly. A Tabela \ref{tab:front_frameworks} descreve cada um destes frameworks.

\begin{table}[h]
\centering
\small
\caption{Componentes Utilizado na Interface Gráfica.}
\label{tab:front_frameworks}
% \begin{tabular}{@{}ll@{}}
% \toprule
% Framework            & Descrição                                                                                                                                                                                                                                                                                                                                                                                                              \\ \midrule
% Twitter Bootstrap   & \begin{tabular}[t]{@{}l@{}}O Twitter Bootstrap é um \textit{framework} para desenvolvimento de \\interface gráfica permite novas criações de forma rápida e simples. \\Conhecido por permitir um desenvolvimento rápido para dispositivos \\móveis, o Bootstrap, possui diversas funcionalidades que são acessados \\através da utilização de JavaScript com CSS.\\ Endereço \url{http://getbootstrap.com} \\ \linebreak \end{tabular} \\
% OpenLayers2         & \begin{tabular}[t]{@{}l@{}}Um dos primeiros e mais utilizados \textit{frameworks} para exibição de \\dados geográficos, o OpenLayers, possui diversas funcionalidades \\para mostrar gráficos em uma página HTML.\\ Endereço\url{http://openlayers.org/two} \\  \linebreak \end{tabular} \\
% jQuery                   & \begin{tabular}[t]{@{}l@{}}Diversas funcionalidades do JavaScript são encapsuladas através deste \\framework tornando o desenvolvimento de páginas dinâmicas mais \\simples. O jQuery permite fazer chamadas XMLHttpRequest (XHR) \\de forma fácil, essas chamadas características de páginas dinâmicas, \\permitem carregar conteúdos de servidores remotos e atualizar a página \\em exibição.\\ Endereço \url{http://jquery.com} \\ \linebreak \end{tabular} \\
% Sly                        & \begin{tabular}[t]{@{}l@{}}Sly, este é um framework para a exibição de imagens em miniaturas onde \\o usuário pode, com o mouse ou com o movimento das mãos, mover as \\imagens de forma dinâmica.\\ Endereço \url{http://darsa.in/sly} \\ \linebreak \end{tabular} \\
% MapServer             & \begin{tabular}[t]{@{}l@{}}O MapServer é um servidor de mapas que permite distribuir dados espaciais \\de forma que estes possam ser renderizados por outros serviços, seguindo \\padrões geográficos como GML, GeoJSON e outros. \\ Endereço \url{http://mapserver.org}  \end{tabular}
% \end{tabular}
\begin{tabular}{| p{2.5cm} | p{12cm} |}
\hline
Framework            & Descrição \\ \hline                                                                                                                                                                                                                                                                                                                                                                                                              
Twitter Bootstrap   & O Twitter Bootstrap é um \textit{framework} para desenvolvimento de interface gráfica permite novas criações de forma rápida e simples. Conhecido por permitir um desenvolvimento rápido para dispositivos móveis, o Bootstrap, possui diversas funcionalidades que são acessados através da utilização de JavaScript com CSS. Endereço \url{http://getbootstrap.com} \\ \hline
OpenLayers2         & Um dos primeiros e mais utilizados \textit{frameworks} para exibição de dados geográficos, o OpenLayers, possui diversas funcionalidades para mostrar gráficos em uma página HTML. Endereço\url{http://openlayers.org/two} \\ \hline
jQuery                   & Diversas funcionalidades do JavaScript são encapsuladas através deste framework tornando o desenvolvimento de páginas dinâmicas mais simples. O jQuery permite fazer chamadas XMLHttpRequest (XHR) de forma fácil, essas chamadas características de páginas dinâmicas, permitem carregar conteúdos de servidores remotos e atualizar a página em exibição. Endereço \url{http://jquery.com} \\ \hline
Sly                        & Sly, este é um framework para a exibição de imagens em miniaturas onde o usuário pode, com o mouse ou com o movimento das mãos, mover as imagens de forma dinâmica. Endereço \url{http://darsa.in/sly} \\ \hline
MapServer            & O MapServer é um servidor de mapas que permite distribuir dados espaciais de forma que estes possam ser renderizados por outros serviços, seguindo padrões geográficos como GML, GeoJSON e outros.  Endereço \url{http://mapserver.org} \\ \hline
\end{tabular}
\end{table}

\pagebreak

Quando a página é exibida, as camadas encontradas disponíveis no servidor local MapServer são carregados. Estas camadas podem ser de um arquivo de Imagem (raster) ou uma camada de pontos (vetorial), o usuário poderá optar por visualizar cada uma destas camadas. Os arquivos de foto, vídeo e áudio que foram foram enviados pelos voluntários são exibidos no sítio, permitindo que o usuário possa interagir com estes. A Figura \ref{fig:UMLFrontEndSequence} ilustra este processo.

\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{figuras/UML/UMLFrontEndSequence.png}
\caption{UML de Sequência do processo de carregamento das camadas, imagens, áudios e vídeos necessárias para o funcionamento da página web do módulo se sensoriamento voluntário.}
\label{fig:UMLFrontEndSequence}
\end{figure}

\pagebreak

Por fim, a Tabela \ref{tab:sumarizacao} faz um breve resumo dos componentes utilizados no desenvolvimento deste projeto descritos nesta seção. Apesar de haver diversos outros componentes com funcionalidades semelhantes a alguns dos componentes selecionados, estes não foram considerados neste trabalho devido à preferência por manter a compatibilidade com outros componentes já em utilização pelo projeto ForestWatchers, como PostgreSQL e MapServer.

% Por fim, a Tabela \ref{tab:sumarizacao} faz uma breve sumarização dos componentes utilizados no desenvolvimento deste projeto descritos nesta seção. Apesar de haver diversos outros componentes com funcionalidades semelhantes a alguns dos componentes selecionados, porém não comparado neste trabalho, devido a preferência de manter compatibilidade com outros componentes já em utilização pelo projeto ForestWatchers, como PostgreSQL e MapServer.

\begin{table}[h]
\centering
% \small
\caption{Sumarização dos componentes utilizados.}
\label{tab:sumarizacao}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|l|c|l|}
\hline
\begin{tabular}[c]{@{}c@{}}Subsistema \\ ou Aplicativo \\ ou Componente\end{tabular}           & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Soluções \\ ou Tecnologias Disponíveis \\ ou Testadas\end{tabular}} & \begin{tabular}[c]{@{}c@{}}Solução \\ Adotada\end{tabular} & \multicolumn{1}{c|}{Motivo}                                                                                                                                                                                  \\ \hline
\multirow{8}{*}{\begin{tabular}[c]{@{}c@{}}Aplicativo \\ para \\ Coleta de Dados\end{tabular}} & Aplicativo de Sistema Pronto:                                                                                      & \multicolumn{1}{l|}{}                                      &                                                                                                                                                                                                              \\
                                                                                               & EpiCollect                                                                                                         & \multicolumn{1}{l|}{}                                      &                                                                                                                                                                                                              \\
                                                                                               & EpiCollect+                                                                                                        & \multicolumn{1}{l|}{}                                      &                                                                                                                                                                                                              \\
                                                                                               & Sensr                                                                                                              & \multicolumn{1}{l|}{}                                      &                                                                                                                                                                                                              \\ \cline{2-4} 
                                                                                               & Aplicativo Nativo:                                                                                                 & \multicolumn{1}{l|}{}                                      &                                                                                                                                                                                                              \\
                                                                                               & Desenvolvido para Windows Phone                                                                                    & \multicolumn{1}{l|}{}                                      &                                                                                                                                                                                                              \\ \cline{2-4} 
                                                                                               & Aplicativo Híbrido:                                                                                                & \multicolumn{1}{l|}{}                                      &                                                                                                                                                                                                              \\
                                                                                               & \begin{tabular}[c]{@{}l@{}}Desenvolvido com PhoneGap,\\ jQueryMobile, Knockout.js\end{tabular}                     & X                                                          & \begin{tabular}[c]{@{}l@{}}Desenvolvimento baseado em \\ Web (HTML5, CSS, Javascript) \\ e disponível para um grande \\ número de plataformas.\end{tabular}                                                  \\ \hline
\multirow{9}{*}{\begin{tabular}[c]{@{}c@{}}Servidor \\ para \\ Internet\end{tabular}}          & Back-End:                                                                                                          &                                                            &                                                                                                                                                                                                              \\
                                                                                               & PostgreSQL                                                                                                         & X                                                          & \begin{tabular}[c]{@{}l@{}}Banco de dados escolhido por\\ ser parte integrante do componente\\ PyBossa, assim não tendo necessidade\\ de instalar diferentes softwares com\\ o mesmo propósito.\end{tabular} \\ \cline{2-4} 
                                                                                               & Flask                                                                                                              & X                                                          & \begin{tabular}[c]{@{}l@{}}Servidor Web escolhido por\\ ser parte integrante do componente\\ PyBossa, assim não tendo necessidade\\ de instalar diferentes softwares com\\ o mesmo propósito.\end{tabular}   \\ \cline{2-4} 
                                                                                               & Front-End:                                                                                                         &                                                            &                                                                                                                                                                                                              \\
                                                                                               & Twitter Bootstrap                                                                                                  & X                                                          & \begin{tabular}[c]{@{}l@{}}Oferece facilidade para o desenvolvimento\\ HTML5\end{tabular}                                                                                                                    \\ \cline{2-4} 
                                                                                               & OpenLayers2                                                                                                        & X                                                          & \begin{tabular}[c]{@{}l@{}}Gerenciamento de mapas para ambiente\\ Web\end{tabular}                                                                                                                           \\ \cline{2-4} 
                                                                                               & Jquery                                                                                                             & X                                                          & \begin{tabular}[c]{@{}l@{}}Facilitador para manusear scripts feitos\\ em JavaScript\end{tabular}                                                                                                             \\ \cline{2-4} 
                                                                                               & Sly                                                                                                                & X                                                          & \begin{tabular}[c]{@{}l@{}}Permite criar miniaturas de imagens ou\\ elementos HTML\end{tabular}                                                                                                              \\ \cline{2-4} 
                                                                                               & MapServer                                                                                                          & X                                                          & \begin{tabular}[c]{@{}l@{}}Responsável por renderizar imagens para\\ mapas em ambiente Web\end{tabular}                                                                                                      \\ \hline
\end{tabular}
}
\end{table}





\chapter{Teste do Módulo de SV}
\label{ch:resultados}

% Of course you can use these images.  These are with Eliana, in the lab of Sidneis students.  These are actually products purchased and processed by the Sectretaria de Meio Ambiente (SEMA) do Estado do Pará.  They are made available to research institutions, for educational purposes.  Please use and if you published anything, please cite and thank SEMA and the Government of Pará.  Thats it!
%  http://www.sema.pa.gov.br/2010/02/09/8665/

A área utilizada para testar o módulo de SV desenvolvido nesta dissertação (Figura \ref{fig:para_exported}) faz parte da Floresta dos Tapajós, uma reserva federal, e seus arredores. Localizado na cidade de Belterra, PA, dentro portanto da Amazônia Legal. Esta é uma região de floresta tropical. O processo de ocupação na região ocorreu ao longo da rodovia BR-163, depois do desmatamento da floresta primária e abertura de novas estradas para a formação de pequenas fazendas. Como resultado deste processo, existem mosaicos de vegetações secundárias em diversos estágios de desenvolvimento. Áreas de  pasto, milharais e solos expostos dentro de florestas \cite{LongoReDeBeRiMe:2012:PhChPa}.

Para o teste do conceito desenvolvido neste trabalho, utilizou-se o aplicativo híbrido (ver Seção \ref{ssub:aplicativo_com_biblioteca_hibrida}) na área de estudo para captar imagens, vídeos e áudios de algum interesse ao projeto FW, como áreas não florestas, clareiras, fazendas ou fauna. Áreas de clareiras, por exemplo, podem apresentar diferentes formas em uma imagem de satélite de baixa resolução espacial tipo MODIS, sendo muitas vezes imperceptível do espaço. Com as fotos obtidas em \textit{in-situ} pelos voluntários é possível complementar e mesmo corrigir os mapas de desmatamento gerados pelos voluntários que apenas têm acesso a imagens de satélite.

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{figuras/para_exported.png}
\caption{Área de interesse.}
\label{fig:para_exported}
\end{figure}

Durante a fase de testes, utilizou-se um dispositivo móvel Lumia 800, um \textit{smartphone} com o sistema operacional Windows Phone, GPS e bússola interna. Para assegurar a qualidade dos dados georreferenciados coletados, foi utilizado em conjunto com o dispositivo móvel uma bússola magnética e também um aparelho Garmin GPSMAP 60CSx\footnote{\url{https://buy.garmin.com/en-US/US/on-the-trail/discontinued/gpsmap-60csx/prod310.html}}.

Durante os 15 dias de experimento em campo, foram feitas 93 capturas com o aplicativo, sendo 83 imagens e 10 vídeos. Não foi possível efetuar captura de áudio devido a um erro no código na biblioteca híbrida PhoneGap na versão 2.9. Neste caso, para testar o \textit{front-end} do módulo, foram utilizados áudios extraídos dos vídeos.

Todos os dados foram capturados e mantidos no aparelho para que pudessem ser sincronizados posteriormente. 

A Figura \ref{fig:mapa_fullscreen} ilustra a interface desenvolvida neste trabalho para exibir os dados coletados, semelhante ao esboço visto na Figura \ref{fig:frontend_mocqup}. A interface contém as miniaturas das imagens e vídeos na parte inferior da tela, permitindo uma rápida seleção baseado no interesse do voluntário. Ao clicar em uma imagem ou vídeo, tanto nas miniaturas quanto nos ícones mostrados no mapa, uma pequena janela é exibida com as propriedades de destaque (canto inferior direito da Figura \ref{fig:mapa_fullscreen}).

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{figuras/resultados/mapa_fullscreen.png}
\caption{Interface gráfica \textit{(front-end)} desenvolvido para a exibição dos dados coletados por voluntários.}
\label{fig:mapa_fullscreen}
\end{figure}

Esta pequena janela é comum para os demais recursos (áudios, vídeos e imagens), porém a primeira linha apresenta um aspecto diferente, conforme o tipo de dado selecionado. Caso venha ser uma imagem, são exibidos as diferentes dimensões desta imagem, caso seja um áudio ou vídeo, uma janela é exibida com o respectivo conteúdo pronto para reprodução (veja Fig. \ref{fig:detalhes_conteudos}).
\begin{figure}%
\centering
\includegraphics[width=0.495\textwidth]{figuras/resultados/detalhe_video.png}
\includegraphics[width=0.495\textwidth]{figuras/resultados/detalhe_foto.png}
\qquad
\includegraphics[width=0.495\textwidth]{figuras/resultados/detalhe_audio.png}
\includegraphics[width=0.495\textwidth]{figuras/resultados/selecao_imagem_foto.png}
\caption{No canto superior esquerdo, uma amostra de um vídeo capturado e pronto para exibição. No canto inferior esquerdo, uma gravação de áudio pronto para ser reproduzida. Na esquerda, o detalhe de exibição de uma foto e a seleção da imagem com melhor resolução, respectivamente na parte superior e inferior }%
\label{fig:detalhes_conteudos}%
\end{figure}

O mapa de fundo da Figura \ref{fig:mapa_fullscreen} é oferecido gratuitamente pelo projeto OpenStreetMaps, comentado na Seção \ref{ch:informacao_geografica_voluntariada}. Porém, a interface permite alternar a exibição dos mapas de fundo através da seleção de camadas definidas no menu de ``Camadas'', no canto superior direito da tela, visto na Figura \ref{fig:layers_menu}. Para este projeto foram definidas algumas camadas para melhor compreender este estudo; estas são:

\begin{figure}[h]
\centering
\includegraphics[scale=0.7]{figuras/resultados/layers_menu.png}
\caption{Menu com camadas para mapa.}
\label{fig:layers_menu}
\end{figure}

\begin{itemize}
    \item \textbf{MODIS (250m).} A imagem MODIS selecionada faz parte do acervo de catálogos de imagens rápidas da NASA, FAS Brazil 7, imagem TERRA 2013216\footnote{\url{http://rapidfire.sci.gsfc.nasa.gov/imagery/subsets/?subset=FAS_Brazil7.2013216.terra.250m}} datado de 04 de Agosto de 2013, semana em que iniciou-se o estudo. Imagens MODIS foram comentadas na Seção \ref{ch:monitoramento_florestas}.
    \item \textbf{SPOT (2.5m).} A imagem SPOT\footnote{\url{http://www.sema.pa.gov.br/2010/02/09/8665/}} possui resolução geográfica de 2.5 metros. Estas imagens, datadas de 11 de Julho de 2009 e 30 de Julho de 2011, são produtos comprados e processados pela Sectretaria de Meio Ambiente (SEMA) do Estado do Pará, são utilizadas para uso acadêmico e estão sendo usadas neste trabalho apenas para realizar comparações com a imagem MODIS do mesmo local, porém com resolução 10.000 vezes maior.
    \item \textbf{Áudios.} Camada de pontos de áudio com suas propriedades.
    \item \textbf{Imagens.} Camada de pontos das imagens com suas propriedades, todas captadas utilizando o aplicativo híbrido.
    \item \textbf{Vídeos.} Camada de pontos dos vídeos com suas propriedades, todas captadas utilizando o aplicativo híbrido.
    \item \textbf{Dados.} Camada de dados captados de sensores externos. Futuramente, será incorporado ao projeto.
    \item \textbf{Rastreio.} Camada de pontos provindos de rastreio. Futuramente, será incorporado ao projeto.
    \item \textbf{Classificação (RNA).} Imagem gerado pela classificação não supervisionada de uma rede neural artificial a partir da mesma imagem MODIS selecionada.
    \item \textbf{Probabilidade (RNA).} Imagem em escala de cinza da probabilidade de classificação da rede neural artificial ao classificar a imagem MODIS selecionada.
    \item \textbf{Outros.} Esta é uma camada agregada de três outros mapas do Brasil: mapa hidrográfico, unidades de conservação e terras indígenas.
    % imagens do dropbox do Eduardo, acredito que esteja no ForestWatchers.
\end{itemize}

Alternando as camadas, é possível verificar mais precisamente a significância do pixel em questão. Uma imagem SPOT tem uma melhor clareza devido a sua resolução ser 10.000 vezes maior do que uma MODIS, o que permite verificar mais cuidadosamente o que há na composição de um pixel MODIS. 

Na Figura \ref{map:crop_map_modis} é possível observar grandes áreas sem florestas, sendo estas os conjuntos de pixels de tom mais claro. Contudo, não é trivial diferenciar um único pixel de uma imagem MODIS para identificar se este representa uma área florestada ou não.

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{figuras/resultados/crop_map_modis.png}
\caption{Interface do módulo vista com a camada MODIS ativa.}
\label{map:crop_map_modis}
\end{figure}


A mesma área é apresentada na Figura \ref{map:crop_map_spot}. Esta camada torna a tarefa de diferenciar um pixel mais fácil, bastando comparar a camada de imagem MODIS com a camada de imagem SPOT, uma vez que esta possui melhor resolução espacial.

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{figuras/resultados/crop_map_spot.png}
\caption{Interface do módulo vista com a camada SPOT ativa.}
\label{map:crop_map_spot}
\end{figure}

Porém, utilizar imagens SPOT, como é o caso deste trabalho, para comparar dois tipos de imagens em diferentes camadas não é viável. Imagens SPOT são pagas, diferente das imagens MODIS. Além do mais, possuem um tempo de revisita diferente (em geral menor). Portanto, imagens, vídeos ou áudios captados \textit{in-situ} mantém sua importância na tarefa de discenir uma área florestada de uma área não-florestada. 

A Figura \ref{map:small_map_modis} mostra a área compreendida pelas coordenadas 54\textdegree55'26.4''W a 03\textdegree07'33''S a 03\textdegree07'04.8''S de uma imagem MODIS. Há uma variação de cor no píxel que está abaixo dos dois pontos de imagem. porém é difícil saber ao certo se este representa uma área florestada ou não. Assim, as imagens \textit{in-situ} adquiridas pelo dispositivo podem dar uma contribuição análoga à camada SPOT. 

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{figuras/resultados/small_map_modis.png}
\caption{Dois pontos de imagem visualizados no mapa com a camada MODIS ativa.}
\label{map:small_map_modis}
\end{figure}

Na Figura \ref{map:small_selected_modis_left} é possível observar o ponto da imagem no mapa com a camada MODIS selecionada e as propriedades deste ponto. Na direita da figura, a imagem capturada pelo aplicativo.

\begin{figure}[h]
\centering
\includegraphics[width=0.495\textwidth]{figuras/resultados/small_selected_modis_left.png}
\hfill
\includegraphics[width=0.495\textwidth]{figuras/resultados/small_modis_left.png}
\caption{Imagem de desmatamento. À esquerda, uma imagem selecionada e uma pequena janela com suas propriedades. À direita imagem capturada exibida em maior resolução. No mapa, uma camada MODIS ativa.}
\label{map:small_selected_modis_left}
\end{figure}

Outra imagem pode também ilustrar a situação nesta área. A Figura \ref{map:small_selected_modis_right} traz respectivamente da esquerda para a direita, uma imagem captada pelo aplicativo com suas propriedades e uma imagem de maior resolução para melhor visualização.

\begin{figure}[h]
\centering
\includegraphics[width=0.495\textwidth]{figuras/resultados/small_selected_modis_right.png}
\hfill
\includegraphics[width=0.495\textwidth]{figuras/resultados/small_modis_right.png}
\caption{Imagem de solo exposto. À esquerda, uma imagem selecionada e uma pequena janela com suas propriedades. À direita imagem capturada exibida em maior resolução. No mapa, uma camada MODIS ativa.}
\label{map:small_selected_modis_right}
\end{figure}

Ambas imagens (Fig. \ref{map:small_selected_modis_left} e \ref{map:small_selected_modis_right}) tornam evidente tratar-se de área não florestada. Porém, utilizando-se apenas a imagem MODIS (Fig. \ref{map:small_map_modis}) falta resolução para se obter uma classificação precisa, mesmo com uma inspeção visual feita por um voluntário.

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{figuras/resultados/small_map_spot.png}
\caption{À esquerda, uma imagem selecionada e uma pequena janela com suas propriedades. À direita imagem capturada exibida em maior resolução. No mapa, uma camada SPOT ativa.}
\label{map:small_map_spot}
\end{figure}

Observando as propriedades das imagens Fig. \ref{map:small_selected_modis_left} e Fig. \ref{map:small_selected_modis_right}, é possível notar uma propriedade interessante. A orientação das imagens condiz perfeitamente com a visão do mapa mostrado na Figura \ref{map:small_map_spot}, uma vez que essas foram capturadas logo no início do polígono desflorestado, e não no interior do mesmo. Assim, é possível observar que a função da bússola é muito importante pois esta fornece em qual direção a foto foi realizada. Caso a direção estivesse errada, a seta poderia mostrar para uma parte florestada e exibir uma imagem não florestada. Ao treinar uma algoritmo supervisionado, este poderia apresentar divergência por causa deste valor, assumindo que fosse 100\% correto.

Resumindo, a existência de vídeos e áudios captados por voluntários, registrando a fauna local, alguma atividade ilícita de desmatamento, áreas de incêndio, sons de tratores, entre outros, pode auxiliar a tarefa de classificação automática de uma imagem satelital, servindo, por exenplo, de \textit{feedback} à rede neural, tornando-a uma rede supervisionada.

\section{Conclusões e Trabalhos Futuros}
\label{ch:conclusoes}

O objetivo deste trabalho foi o de propor, desenvolver e testar um módulo de sensoriamento voluntário e integrá-lo ao projeto ForestWatchers. A solução foi desenvolver um aplicativo híbrido em que voluntários que possuam diferentes tipos de dispositivos possam contribuir, captando áudio, vídeo e imagens. Junto com o aplicativo, foi desenvolvido um módulo web para exibição dos dados.

O aplicativo foi desenvolvido utilizando o \textit{framework} PhoneGap, que permite utilizar um único código para gerar aplicativos em outras plataformas de forma fácil, até mesmo por linha de comando. O código foi escrito usando a convenção do PhoneGap (HTML, CSS e JavaScript). Os componentes JQueryMobile e KnockOutJS foram utilizados para desenhar a interface gráfica do aplicativo. Porém, antes de concluirmos que o aplicativo deveria ser híbrido, foram testados duas outras soluções para o desenvolvimento do aplicativo. A primeira, utilizando bibliotecas nativas, exigia que cada aplicativo fosse desenvolvido na sua respectiva plataforma desde o princípio. Posteriormente, foi verificado o uso de \textit{frameworks} coleta de dados, como EpiCollect e Sensr como uma solução. Por não ter controle das funcionalidades e os \textit{frameworks} mais modernos serem desenvolvidos para apenas uma única plataforma, esta abordagem foi também descartada.

O módulo de SV aqui desenvolvido obtém informações dos sensores de câmera (para a captura de imagem e vídeo), microfone (áudio), localização (GPS), orientação (bússola). Os dados são armazenados no dispositivos para serem enviados posteriormente, seguindo um modelo de envio por demanda, quando o usuário solicitar. Desta forma, o tráfico de arquivos grandes como vídeo e áudio podem ser feitos através de redes WiFi ao invés de conexões 3G.

O back-end web é encarregado de receber os dados enviados pelos voluntários e armazená-los adequadamente nos bancos de dados, assim como enviar os dados solicitados pela interface web (o front-end do módulo) para a exibição dos resultados. Cada recurso (imagem, áudio ou vídeo) possui sua respectiva coordenada e outras propriedades. 

O módulo de SV foi desenvolvido utilizando Python e o \textit{microframework} Flask com suas extensões, voltado ao desenvolvimento de aplicações web e comunicação web. Um servidor de comunicação web baseado na arquitetura REST foi também desenvolvido, utilizando o protocolo HTTP.

A interface gráfica (front-end) exibe os dados e resultados enviados pelos voluntários. Esta interface é na forma de uma página web que utiliza-se do mesmo servidor (Flask) do back-end. A página exibe os dados georreferenciados utilizando componentes de mapas.

A interface foi desenvolvida em HTML5, CSS3 e JavaScript. Utilizou-se a biblioteca OpenLayers v2 para posicionar cada recurso em sua coordenada que foi captada e mostrar diversos outros mapas ao fundo, dando o poder ao usuário de alternar estes mapas em um sistema de camadas, onde o último selecionado sobrepõe o primeiro. Porém, sempre mantendo os recursos por cima. Outros componentes também foram utilizados na confecção desta página web, como o \textit{framework} de HTML5 Twitter Bootstrap na sua versão 3, permitindo de forma rápida e fácil a criação de sistemas de \textit{grid} para o posicionamento de conteúdo, janelas modais e de interações, menus e barras para navegação. Por último, o componente Sly foi utilizado para mostrar miniaturas dos recursos retornado pelo módulo web, facilitando a iteração do usuário com os dados a serem visualizados. Este também permite acesso por toque, sendo imprescindível no uso para \textit{tablets} e \textit{smartphones}, dispositivos capazes de toque.

Para testar o módulo proposto neste trabalho, o aplicativo foi utilizado em uma área do Estado do Pará, próximo a Belterra. O aplicativo captou fotos e vídeo para serem sincronizados posteriormente com o módulo web. Nesta etapa, não foi possível validar o sistema de captura de áudio devido a um erro no código encontrado na versão do PhoneGap para o sistema Windows Phone e por a área não possuir comunicação com internet. Os dados apresentados neste trabalho para o áudio são representativos e foram gerados a partir da extração do áudio dos arquivos de vídeos captados.

% There're few alternatives still:
% http://2lemetry.com79
% http://exosite.com47
% https://www.carriots.com43
% https://www.grovestreams.com121
% https://thingspeak.com106
% http://openenergymonitor.org52
Como trabalhos futuros, pretende-se integrar ao módulo outros tipos de dados. Existem diversos sítios que permitem compartilhar dados de sensores ambientais pela internet\footnote{\url{https://thingspeak.com}}. Estuda-se agregar tais dados ao projeto permitindo uma visão geral do meio ambiente. 
% Alguns institutos na Ásia e África permitem realizar o monitoramento online de animais, como é o caso de \textit{SAVE THE ELEPHANTS}\footnote{\url{http://savetheelephants.org}} e \textit{SAVE TIGERS NOW}\footnote{\url{http://www.savetigersnow.org}}.