\chapter{Introdução}
\label{ch:introducao}
\section{Objetivos}
\label{ch:objetivos}

Esta dissertação tem como objetivo, formalizar a integração dos módulos já desenvolvidos (ver figura \ref{fig:estrutura_atual}), para a definitiva automatização do processo de análise de uma nova área de interesse, e adicionar à arquitetura existente a capacidade de coletar dados in-situ, característica principal de um projeto de ciência cidadã do tipo de sensoriamento voluntário, utilizando-se de dispositivos móveis utilizados pelos voluntários.

\subsection{Objectivos Específicos}
\label{ch:objetivos:especificos}

Os objetivos específicos desta pesquisa são:

\begin{enumerate}
    \item Validar o conceito de sensoriamento voluntário.

    \item Propor e desevolver um módulo de sensoriamento voluntário.

    \item Integrar o módulo de sensoriamento voluntário junto ao projeto \textit{ForestWatchers}.

\end{enumerate}

\section{Organização do Documento}
\label{ch:organizacao}
Este documento está organizado da seguinte forma: O Capítulo \ref{ch:monitoramento_florestas} é feita a revisão bibliográfica das ferramentas de monitoramento de florestas criado pelo INPE e suas metodologias. Uma revisão do tópico de ciência cidadã é abordado no Capítulo \ref{ch:ciencia_cidada}, onde é realizada uma comparação com as pesquisas científicas realizadas por voluntários antigamente e nos tempos atuais, conhecida por ciencia cidadã moderna. No Capítulo \ref{ch:forestwatchers} é comentado sobre o projeto ForestWatchers, a definição do projeto, a metodologia empregada e as aplicações feitas por este. As metodologias e resultados deste trabalho são apresentados no Capítulo \ref{ch:metodologia} e \ref{ch:resultados}, respectivamente. Para finalizar, as conclusões são feitas no Capítulo \ref{ch:conclusoes}.

\chapter{Monitoramento de Florestas}
\label{ch:monitoramento_florestas}

Por mais de duas décadas, o Brasil vem utilizando imagens de satélites (ver figura \ref{fig:comparacao_resourcesat_modis}) para realizar o monitoramento da Amazônia \cite{Monteiro2008}. Estes sistemas, desenvolvidos pelo INPE, tornaram o Brasil uma referência mundial na área \cite{Tollefson2012a}. \citeonline{Kintisch2007} afirma que esse sistema é motivo de admiração mundial por ser capaz de informar anualmente as estimativas de taxas de desmatamento na Amazônia, além de emitir alertas semanais para as autoridades pertinentes. Os principais sistemas utilizados pelo INPE na tarefa de monitorar o desmatamento são descritos nas seções a seguir.

\section{PRODES}
\label{ch:prodes}

Em 1988, o Projeto de Monitoramento do Desmatamento na Amazônia Legal (PRODES) foi desenvolvido para fornecer informações sobre a dinâmica anual do desmatamento de cobertura florestal na Amazônia Legal. As estimativas geradas pelo PRODES são anuais devido à complexidade e ao detalhamento necessários para o cálculo da área de desmate. Essas estimativas se baseiam em mapeamento detalhado com um grande conjunto de imagens do tipo LANDSAT (ou equivalente) , que cobrem a Amazônia com baixa frequência temporal (16 e 26 dias, ver figura \ref{fig:swath_width_LANDSAT-NASA}) e com resoluçãoção espacial entre 20 e 30 metros. Esses sensores são capazes de mapear desmatamentos cujas áreas sejam superiores a $6,25$ hectares \cite{Monteiro2008}.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figuras/swath_width_LANDSAT-NASA.jpg}
    \caption{\textit{Swath} do LANDSAT, largura da cobertura diária realizado pelo LANDSAT, ilustrado no continente Norte Americano. Para obter toda a extensão amazônica é necessário de 16 a 26 dias, dependendo das condições climáticas do local.  }
    \FONTE{\citeonline{NASA}}
    \label{fig:swath_width_LANDSAT-NASA}
\end{figure}

\subsection{Metodologia}
\label{ch:prodes_metodo}

Para realizar o cálculo da taxa de desmatamento as imagens são selecionadas de modo a obter a menor cobertura de nuvens possível, melhor visibilidade com uma adequada qualidade radiométrica\footnote{A resolução radiométrica é dada pelo número de valores digitais representando níveis de cinza, usados para expressar os dados coletados pelo sensor. Quanto maior o número de valores, maior é a resolução radiométrica} e com a data de aquisição das imagens próxima ao período de referência para o cálculo da taxa de desmatamento. Porém, considerando o histórico climatológico da Amazônia, a maioria das imagens não se apresentam livres de nuvens. Por isso é possível utilizar mais de uma imagem (inclusive de outros satélites) para compor as cenas, formando um mosáico (ver figura \ref{fig:prodes_mosaico}). 

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figuras/mosaico_landsat-prodes.png}
    \caption{ Mosaíco formado por imagens LANDSAT a serem utilizadas no sistema PRODES.}
    \FONTE{\citeonline{INPE}}
    \label{fig:prodes_mosaico}
\end{figure}

Após a seleção das imagens, a próxima etapa envolve transformar seus dados radiométricos em componentes de cena (vegetação, solo e sombra), utilizando o Modelo Linear de Mistura Espectral (MLME). As bandas 3, 4 e 5 do sensor TM são utilizadas para estimar a proporção dos componentes solo, vegetação e sombra para cada pixel, formando um sistema de equações lineares que pode ser solucionado pelo método dos mínimos quadrados ponderados. O resultado desse modelo linear é uma imagem-fração, onde se tem três bandas sintéticas com os valores proporcionais de vegetação, solo e sombra. A segmentação\footnote{Segmentação de imagem é uma técnica de agrupamentos de dados onde características espectrais semelhantes são agrupadas.} da imagem-fração é então realizada, ajustando-se os limiares de similaridades e de área. 

Um algoritmo de classificação não-supervisionado de agrupamentos de dados trata as imagens segmentadas, classificando-as de acordo com as classes definidas pelo banco de dados. Como resultado tem-se uma nova imagem \textit{raster} ou vetorial com as áreas desflorestadas. Então, um fotointerprete tem a tarefa de analisar os polígonos temáticos gerados, tomando a decisão se esses devem ser aceitos ou reclassificados. Uma vez essa imagem aceita, uma máscara de desmatamento contendo as áreas de corte raso já detectados é gerada. Essa máscara será utilizada para eliminar desmatamentos antigos, impedindo que sejam identificados novamente.

\section{DETER}
\label{ch:deter}\ref{}

Devido ao tempo necessário para gerar os resultados e por observar apenas áreas de corte raso, o PRODES não pode ser utilizado como um sistema de prevenção. Portanto, a partir de 2004 o Sistema de Detecção de Desmatamento em Tempo Real (DETER) foi implementado para realizar o monitoramento contínuo do desmatamento e da degradação florestal. Esse sistema foi criado para atender ao Governo Federal no Plano de Ação para a Prevenção e Controle do Desmatamento na Amazônia Legal. O principal objetivo desse sistema é de fornecer informações sobre o local e a dimensão aproximada de ocorrências de mudanças na vegetação de modo a agilizar a fiscalização. 

\subsection{Metodologia}
\label{ch:deter_metodo}

As imagens utilizadas por esse sistema são obtidas pelo sensor MODIS (a bordo do satélite TERRA da NASA), que cobre a Amazônia a cada dia e meio (ver figura \ref{fig:swath_width_MODIS-TERRA}. Essa alta resolução temporal reduz as limitações de observação impostas pela cobertura de nuvens da região. Com a máxima resolução espacial limitada em $250$ metros, as imagens desses sensores permitem a detecção de desmatamentos apenas para áreas maiores do que $25$ hectares. O objetivo do DETER é de fornecer indicadores para fiscalização a cada 15 dias, quando as condições de observação são favoráveis. Esse sistema observa diversos estágios de desmatamento para emitir seus alertas, como o de corte raso, degradação florestal de intensidade alta, média e baixa, sendo o último mais difícil devido a resolução das imagens do sensor MODIS \cite{Monteiro2008}.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figuras/swath_width_MODIS-TERRA.jpg}
    \caption{\textit{Swath} do MODIS, largura da cobertura diária obtida a cada sobrevoo. Para obter toda a extensão amazônica é necessário em média um dia e meio.}
    \FONTE{\citeonline{NASA}}
    \label{fig:swath_width_MODIS-TERRA}
\end{figure}

A aquisição das imagens é feita de forma rápida, uma vez que que o DETER utiliza os produtos baseados em \textit{granules}\footnote{Granules são produtos gerados de uma área particular. Granules não cobrem todo o globo.} dos subconjuntos de resposta rápida da NASA. Esses dados encontram-se prontos para serem utilizados, pois já foram processados, disponibilizados em GeoTIFF, RGB-equivalente, no formato de 8-bits e geograficamente projetados. 

Essas imagens são então carregadas no Sistema de Processamento de Informações Geo-referenciadas (SPRING) para que outros processamentos sejam feitos. Nesta etapa o especialista necessita aplicar um modelo de mistura para separar o que é floresta, solo ou água (ou sombra). Essa etapa é feita selecionando-se certos \textit{pixels} com uma resposta espectral particular. Então, cada imagem é segmentada e classificada. Após a classificação das imagens, o especialista aplica as máscaras dos desflorestamentos anteriores e de hidrografia, com a finalidade de esconder os desmatamentos já conhecidos assim como outras características. 

Na última etapa, o especialista corrige os resultados da segmentação automática, pixel-a-pixel. As vezes é possível que as etapas de classificação e segmentação possam ser colocados de lado, pois o especialista pode extrair todas as informações baseando-se apenas em sua expertise olhando para as imagens do satélite, munido dos arquivos geográficos de desflorestamento e hidrografia.

\begin{figure}[htb]
\includegraphics[width=0.485\textwidth]{figuras/COMPARE_RESOURCESAT.png}
\hfill
\includegraphics[width=0.485\textwidth]{figuras/COMPARE_MODIS.png}
\caption{Comparação de diferentes resoluções espaciais. À esquerda, uma imagem RESOURCESAT com 23,5 m por pixel. À direita, uma imagem MODIS com 250 m por pixel.}
\label{fig:comparacao_resourcesat_modis}
\end{figure}



\chapter{Ciência Cidadã}
\label{ch:ciencia_cidada}

Ciência cidadã é o termo usado para designar projetos no qual voluntários, muitos sem nenhum treinamento científico específico, efetuam ou gerenciam tarefas científicas, tais como a realização de observações, medições ou computação \cite{SoaresSant:2011:EnPoAt}. 

Através do voluntariado de pessoas ordinárias, conhecidas como cientistas cidadão, projetos científicos conseguem obter um quadro maior de colaboradores \cite{Cohn.2008}. Um fator importante em projetos grandes, agilizando o processo de aquisição e divulgação dos resultados. Segundo \citeonline{Silvertown2009}, o cientista cidadão é um voluntário que coleta ou processa dados como parte de uma investigação científica. Cientistas cidadão não são responsáveis, necessariamente, por analisar ou publicar artigos científicos, estes desempenham tarefas simples, mas de grande importância para a conclusão dos trabalhos científicos. Nas últimas décadas, projetos científicos baseados em ciência cidadã ganharam notoriedade, porém esta abordagem não é nova para a comunidade científica. 

Realizar pesquisas cientificas utilizando-se da colaboração de diversos indivíduos vem de tempos remotos. Para ilustrar, A Origem das Espécies é um exemplo de pesquisa científica realizada com a ajuda de diversos colaboradores já em 1830. \citeonline{darwin-origin-of-species-1859}, contou com a ajuda de mais de 2000 colaboradores entre esses, especialistas, biólogos e pesquisadores de diferentes áreas, tendo também a colaboração de cientistas de diferentes áreas.  O projeto \textit{\textbf{Darwin Correspondences}}\footnote{\url{http://www.darwinproject.ac.uk/}} reune mais de 7.500 das cartas que Darwin manteve com seus correspondentes durante sua pesquisa \cite{DarwinProject_Correspondents}. 

Os conteúdos destas cartas variavam de notações científicas sobre algumas espécies, o que requeria um aparato profissional, ou de apenas simples observações, que vieram a colaborar com teoria da evolução das espécies. Naquela época, as cartas demoravam meses para serem recebidas e lidas,  o processo de responder uma carta e obter um novo retorno da mesma pessoa, chegava a levar questões de anos para acontecer. Tudo isto devido a este meio de comunicação não ter as mesmas tecnologias atuais, tornando a tarefa de entregar uma carta hoje em dia simples e comum , um trabalho dificultoso e lento. Naquela época, os serviços de correspondências era feito por mensageiros a pé, a cavalo ou através de charretes, tendo návios à vela para correspondências pelos mares. \citeonline{Hyde1891} relembra que para a determinada época, estes serviços eram caros e não acessível para todos, o que dificultava ainda mais o compartilhamento de ideias. Em 1840, com a grande reforma britânica de postagem,  \textit{Penny Postage} \footnote{A reforma realizada pela \textit{Royal Mail} do Reino Unido cobrava apenas um \textit{Penny}, menor moeda do sistema monetário da época, para entregar as cartas indiferente da distância.}, houve uma maior difusão e uso dos serviços, elevando o envio de cartas de 82.500.000 para 169.000.000 em um ano, mais que o dobro.

\citeonline{Zimmer2011}, comenta que os resultados obtidos no recente trabalho de \citeonline{Silvertown2011} seria uma das formas que Darwin faria ciência hoje através da Internet. Neste trabalho, \citeonline{Silvertown2011} observa mudanças evolucionárias de um continente através de colaboradores que utilizaram um projeto de ciência cidadã moderno, Evolution MegaLab, iniciado em 2008 o projeto contava com colaboradores para enviar informações de duas espécies de caramujos, Cepaea nemoralis and C. hortensis, para realizar um estudo de evolução da espécie observando as diferentes cores de suas cascas.

Um projeto da universidade de Oxford irá investigar o envolvimento do público na ciência do século 19 e 21 \cite{conscicom2014}, receberá o financeamento de quase 2 milhões de libras para realizar seus estudos. Supõe-se que este estudo poderá entender e desenvolver novas ferramentas para trocar informações entre cientistas profissionais e legiões de voluntários \cite{Leicester2013}. 

\section{Ciência Cidadã Moderna}
\label{ch:ciencia_cidada_moderna}

O projeto considerado um dos primeiros de ciência cidadã moderno é o \textit{Christmas Bird Count}. Um projeto antigo e que ainda encontra-se em atividade, o Christmas Bird Count procura contar as diferentes espécies que existem na américa do Norte, suas eventuais mudanças de habitat, entre outras informações. Idealizado em 1900 por Frank Chapman, um famoso ornitólogo do Museu Americano de História Natural, como uma atividade alternativa ao evento de caça aos pássaros existente na época, Chapman publicou diversos livros com os resultados obtidos por este projeto com a ajuda de milhares de voluntários. Estes seguem diversas regras para conduzir a pesquisa durante os 20 dias em que as observações são feitas, de 14 de dezembro a 5 de janeiro de cada ano, só podem ser contabilizados os pássaros que forem avistados ou ouvidos em um diâmetro de 24-km, moradores próximos a estas áreas podem utilizar bebedouros para pássaros para atrair mais espécies e contabilizá-los \cite{Silvertown2009}. Em uma contagem recente milhares de observadores relataram mais de $63$ milhões de pássaros. 

Hoje, o centro de pesquisa que deu origem a este projeto é considerado um dos maiores centros especializados em ciência cidadã com diversos estudos em biologia. Cientistas do laboratório Cornell de Ornitologia universidade de Cornell, lídereres no estudo e conservação dos pássaros, rastreiam projetos que utilizam ciência cidadã para realizar seus estudos. Estes acreditam que trabalhar com cientistas cidadãos é um fenômeno em expansão em todo o mundo \cite{Cohn.2008}. Este laboratório conta com uma comunidade de aproximadamente 200 mil participantes de ciência cidadã.

Ainda há dúvidas se os projetos de ciência cidadã possam gerar resultados confiáveis, uma vez que muitos dos voluntários engajados nas atividades científicas não possuem conhecimento nem mesmo familiarização com as ferramentas de coleta. Esta é uma questão muito pertinente e recorrente do meio. Há evidências \cite{Silvertown2009,Silvertown2011,Cohn.2008} que estes dados produzidos por cidadãos comuns possam sim ser confiáveis. Para isto é necessário que algumas medidas sejam seguidas.

Para alguns tipos de projetos, \citeonline{Cohn.2008} defende que os voluntários devem possuir algum tipo de treinamento básico, para que os dados sejam coletados conforme o solicitados pelos cientistas, assim diretrizes devem ser definidas. Parte dessas diretrizes devem limitar o trabalho do voluntário, especificando um determinado foco de coleta, por exemplo. Esta especificação evita diversos ruídos nos dados e ao comparar a coleta feita entre os voluntários, os dados seguirão a mesma semântica, facilitando a verificação de erros. Há relatos que projetos anteriores baseados em ciência cidadã, possuiam resultados variados por causa destes, ao invés de dados exatos \cite{Cohn.2008}. Solicitar que os voluntários desempenhem trabalhos simples auxilia na exatidão dos dados. 

\cite{Silvertown2009} enumera três fatores cruciais para o aparecimento de projetos de ciência cidadã nos últimos anos. Primeiramente, a Internet como meio de disseminar informações e adquirir dados do público, assim como a tecnologia dos smartphones, onde mais e mais aplicativos destes utilizam diversos sensores para coletar diferentes dados. Segundo fator se deve aos cientistas profissionais perceberem que voluntários são uma fonte sem custos de trabalho e habilidades pessoais como também de poder computacional, projetos que requerem adquirir diversos dados ao longo do globo, necessitam de ajuda, podendo ser de voluntários, para se obter sucesso. Terceiro fator, grandes fundadores de projetos científicos procuram beneficiar projetos que utilizam cientistas cidadãos em seus trabalhos.

Com o aparecimento destes novos projetos, a ciência cidadã moderna pode ser classificadas em três formas, conforme o nível de envolvimento do voluntário e a tecnologia utilizada no projeto (ver figura \ref{fig:pt_citizen_science}).

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figuras/pt_citizen_science.png}
    \caption{A ciência cidadã pode ser classificadas em três formas: computação voluntária, onde os voluntários doam o poder computacional de suas máquinas para pesquisas científicas; pensamento voluntário utilizado em projetos que requerem a cognição dos voltuntários, como classificação de imagens; e sensoriamento voluntário onde a captação de dados é crucial para ter uma pesquisa.}
    \label{fig:pt_citizen_science}
\end{figure}

Estas formas serão introduzidas a seguir.

\section{Computação Voluntária}
\label{ch:computacao_voluntaria}

Recentemente, o número de projetos que se beneficiam de ciência cidadã está aumentando, cada dia há novos projetos surgindo. Estes projetos chamados de ciência cidadã moderno estão se tornando frequente por causa da accebilidade das tecnologias atuais, o que não requer aparatos especializados para realizar as pesquisas. Como mencionado anteriormente, as informações que \citeonline{Darwin1859} utilizou em suas pesquisas foram enviadas através de cartas que demoravam muitos meses. Hoje, com o avanço da internet, voluntários em diferentes partes do mundo podem fornecer diferentes tipos de dados a uma pesquisa. Seja por dispositivos móveis, que uma vez ligados a internet podem fornecer dados de qualquer lugar, ou então por meio de computadores. 

Na década de 80, a internet ainda era apenas um embrião e poucos tinham acesso. Existiam menos de 200,000 servidores espalhados no mundo. Até então não existiam páginas para serem navegadas, a principal forma de troca de mensagem era através de e-mail, criado em 1977 \cite{HistoryOfInternet:David,HistoryOfInternet:Anthony}, outros meios eram por telnet e IRC, apenas. Só no início da década de 90 que as primeiras páginas de internet foram criadas, após a definição do \textit{WWW}\footnote{World-Wide Web} criado por \citeonline{berners1992world}. A internet estava tornando-se popular, com seus aproximados 1 milhão de servidores e suas 50 páginas de internet.

Com a popularização da internet, iniciou-se a aparição de projetos notáveis da ciência cidadã moderna. Os computadores desta época eram caros e possuiam pouco poder computacional, apenas grandes indústrias e universidades tinham acesso a máquinas de grande desempenho. Neste período, surgiram os primeiros projetos de computação voluntária, onde os voluntários doavam o tempo de processamento ocioso de suas máquinas a projetos que necessitavam de grande poder computacional para trabalhar em cima dos seus dados. O conceito desta forma de projeto era de dividir a grande massa de dados existente em pequenas porções que fossem possíveis para os voluntários efetuar downloads, visto que naquela época não havia internet de banda larga. A forma de conexão à internet ainda era discada e o modem mais rápido deste período era o de 56k\footnote{56 kilobits por segundo} \cite{AndersonCKLW02}.

No meio da década de 90, surgiu os projetos \textbf{\textit{GIMPS}}\footnote{\textit{\url{http://www.mersenne.org/}-Great Internet Mersenne Prime Search}} e \textbf{\textit{Distributed.net}}\footnote{http://www.distributed.net/}\cite{Anderson1999,AndersonCKLW02,Hayes1998}.

\textit{GIMPS} foi primeiro projeto de computação voluntária de grande porte a ser realizado, \textit{GIMPS}, tinha como objetivo encontrar números primos de Mersenne, nome dado em homenagem ao estudioso Marin Mersenne da teoria dos números. A formula destes números equivale  $ M_n = 2^n -1 $, onde $n$ é um número natural. O desafio de descobrir números de Mersenne está diretamente ligado ao fato destes números serem exponênciais, tendo assim milhares de dígitos em sua composição. Até 1996, início do projeto \textit{GIMPS}, apenas 34 números primos de Mersenne eram conhecidos, logo no primeiro ano do projeto foram descubertos mais dois  números, $ M_{1398269} $ e $M_{2976221}$. O primeiro número possui $852.365$ algoritmos, o segundo $1.814.262$, uma operação que seria impossível para ser realizada por uma pessoa. Ambos foram descobertos na primeira versão do software disponibilizado pelo projeto, sendo calculado por um computador Pentium 90 MHz e Pentium 100MHz, respectivamente. Hoje, há o conhecimento de 48 números de Mersenne, sendo o último número descoberto o $M_{57885161}$ com $17.425.170$ dígitos em 2013, desde o início do projeto foram descobertos 14 destes números \cite{Marsenne:Primes,Hayes1998}.

A \textit{Distributed.net}, lançado em 1997, tinha o principal objetivo de quebrar a criptografia gerada pela empresa RSA, para o desafio \textit{RSA Secret-Key Challenge} que correspondia a uma chave de 56-bit e possuia uma recompensa de $10.000,00$ dólares. O projeto criado por Earle Ady e Christopher G. Stach II, contava com a colaboração de mais de $300.000$ voluntários utilizando o tempo de seus computadores realizando Força Bruta\footnote{Força Bruta é a forma de tentar obter a a resposta de uma senha através de ínumeras tentativas.} em cima de parte do código disponibilizado para o desafio. Em 250 dias a chave foi descoberta, utilizando um poder computacional equivalente a 26 mil \textit{Pentium 200}. Outro desafio com uma chave de 64-bit também foi concluído após 4 anos e o prêmio pago. A empresa de segurança RSA, havia dito que para quebrar uma chave de 64-bit, seria necessário mais de 100 anos testando todas as possibilidades e combinações. Atualmente o projeto está focado em quebrar uma chave de 72-bit \cite{distributed.net:online,Distributed.net:wired}. 

Em 1999, \citeonline{AndersonCKLW02} iniciou um dos primeiros e bem sucedido projeto de ciência cidadã, o objetivo deste projeto era de encontrar vida inteligente no espaço, através da análise de sinais de rádios captadas do espaço, \textit{SETI@Home}. Porém para conseguir analizar esses sinais, o projeto contou com o uso de diferentes computares, todos espalhados pela internet formando um grande sistema distruído de processamento. Os voluntários que se cadastravam no site podiam fazer download de um aplicativo que só era ativado quado o computador estava em modo ocioso, o aplicativo recebia pacotes de sinais a serem analizados e no fim do processamento enviava os resultados obtidos ao servidor do projeto.

\section{Pensamento Voluntário}
\label{ch:pensamnto_voluntario}

\cite{Anderson1999}, a frente do projeto \textit{SETI@Home}, iniciou o desenvolvimento de uma nova ferramenta para diminuir as barreiras que ele havia encontrado ao longo do desenvolvimento de seu projeto, viabilizando assim novas iniciativas para utilizar computação voluntária de forma rápida e sem grandes conhecimentos de computação. Outra função da ferramenta, BOINC\footnote{Berkeley Open Infrastructure for Network Computing}, era de avaliar a exatidão e veracidade dos dados antes de enviá-los aos servidores dos projetos \cite{anderson2003public}. Esta ferramenta já foi utilizada por mais de 150 projetos, tendo atualmente 70 projetos online. Estes fatos só foram alcançados pela acessibilidade que novos projetos do tipo de computação voluntária tiveram com a criação da nova ferramenta e também pela visibilidade que a ferramenta deu aos projetos deste porte.

No fim da década de 90, \citeonline{dinucci1999fragmented} cunhou o termo \textit{Web 2.0} dizendo que a internet até então não tinha mostrado o seu real potencial. As páginas eram simplesmentes recursos estáticos onde a navegação era composta de uma simples requisição a este recurso e o recurso era então exibido na tela dos computadores da época. A revolução da \textit{Web 2.0} seria marcada pela interatividade do conteúdo, permitindo a qualquer pessoa utilizando de um computador ou dispositivo móvel, não mais carregar um simples recurso estático, mas sim o poder de interagir com este recurso, expressando ideias e adicionando novas informações a \textit{Web}. Diversas novas ferramentas foram criadas nesta nova era. Diferentes tipos de \textit{blogs}, \textit{wikis} e páginas de internet repletos de conteúdos dinâmicos.

Além da ferramenta \textit{BOINC} realizar verificações redundantes para melhorar a exatidão dos resultados, esta também era uma plataforma de pontuação. Na página da ferramenta existem diversas estatísticas dos projetos em andamento, estas estatísticas são atualizadas dinâmicamente conforme os resultados são submetidos pelos voluntários. Uma vez que os novos resultados são submetidos e aprovados, cada voluntário tem o valor da sua contribuição ao projeto calculado novamente. Tendo assim um sistema de creditos, que pontua a participação dos voluntários, destacando os que mais contribuem. Este é considerado o sistema de recompensa dos usuários, levando o projeto a ter cada vez mais voluntários contribuindo com a performance da sua máquina para ganhar notoriedade \cite{Anderson1999}.

Com a possibilidade de conteúdo dinâmico e a interação dos usuários, sugiram novos tipos de projetos que passaram a utilizar a capacidade cognitiva dos voluntários para analisar visualmente determinados dados e em função destes tomar ações. 

Um dos primeiros projetos de pensamento voluntário foi criado para detectar pequenas partículas de poeira interestelar coletada pela mssão \textit{Stardust} da NASA, lançado em 1999 \cite{Stardust:Mission}. Andrew Westpahl, o idealizador do projeto \textit{Stardust@Home} teve a ideia de utilizar a percepção dos usuários para substituir a falta de uma tecnologia de reconhecimento de padrão capaz de encontrar as partículas mínusculas coletada pela missão. Westpahl, estima que levaria mais de um século para sua equipe poder atingir o objetivo do projeto sem a ajuda dos voluntários. Para encontrar as partículas, foi disponibilizado no início do projeto em 2006, 1.6 milhões de imagens na página do projeto, estas imagens recriam a experiência que um cientista exerceria se estivesse analisando as amostras atrás de particulas através de um microscópio, estabelecendo uma melhor imagem ajustando o seu foco. Estas 1.6 milhões de imagens, foram feitas para simular esta função, chamado de ``filmes de foco'', onde diversas imagens foram feitas de um determinado ponto mas utilizando posições diferentes para se ter uma melhor nitidez da imagem ou não. É função do voluntário verificar se esta imagem esta bem focada, verificando a nitidez das imagens disponibilizadas e se há alguma particula presente em alguma destas imagens\cite{Hand2010}. Caso não exista nenhuma imagem focada, o voluntário deve informar através do site esta situação, assim como outras diveras situações que podem acontecer. Para conhecer essas determinadas situações, os voluntários necessitam realizar um treinamento antes de iniciar o seu trabalho de voluntário efetivamente, neste treinamento há dicas e orientações de como proceder. Este tipo de treinamento de qualificação é muito comum em projetos de ciência cidadã \cite{Silvertown2009,Anderson1999}.

Apesar do projeto \textit{Stardust@Home} possuir o sufixo \textit{@Home}, este não utiliza a ferramenta BOINC, idealizada por \citeonline{anderson2003public}. Este sufixo é apenas uma homenagem aos projetos de ciência cidadã, efetuado por estes. Contudo, \citeonline{Anderson1999} estudou o projeto e idealizou uma nova ferramenta para tornar projetos de pensamento voluntário mais comuns, assim como o uso da ferramenta BOINC. BOSSA\footnote{\url{http://boinc.berkeley.edu/trac/wiki/BossaIntro}} é um \textit{middleware} responsável por dividir o trabalho em tarefas menores e atribuí-las aos voluntários, realizando verificações do nível de acertividade das respostas dadas pelos voluntários através de redundância das tarefas. 

Em 2007, iniciou-se o projeto \textit{GalaxyZoo} com o objetivo de classificar imagens de galaxias. As imagens captadas por um telescópio robótico, \textit{Sloan Digital Sky Survey}\footnote{http://www.sdss.org/} era apresentadas para os voluntários e estes haviam de decidir se a imagem continha alguma galáxia, se houvesse, qual era a sua forma eliptica ou espiral, se fosse esta última, ainda havia uma última pergunta, qual o sentido da sua rotação\cite{Hand2010}. Pelo número de imagens que deveriam ser classificadas os cientistas envolvidos acreditavam que iria demorar mais de 2 anos para que todas as imagens fossem classificadas\cite{GalaxyZooAbout}. Porém, com apenas um dia de funcionamento, o \textit{GalaxyZoo} conseguiu reunir 35 mil voluntários que fizeram aproximadamente 1.5 milhões de classificações. \citeonline{Raddick2009b} compara o resultado obtido em um dia com a de um aluno de graduação que em uma semana conseguiu classificar apenas 50 mil galáxias. O projeto classificou perto de um milhão de galáxias utilizando-se de mais de 150 mil voluntários. Em sua segunda versão, o \textbf{GalaxyZoo} contou com mais de 200 mil voluntários para classificar de forma mais detalhada 300 mil galáxias previamente classificadas \cite{willett2013galaxy}. 

\textit{Rosseta@Home} outro importante projeto de ciência cidadã. Quando criado em 2005, este projeto seguia a mesma tendência do \textit{Seti@Home} assim como os demais projetos da família \textit{@Home}, ser mais uma computação voluntária. O objetivo deste projeto é de utilizar o grande poder computacional reunido para prever o enovelamento de proteínas, um processo químico em que a estrutura de uma proteína assume a sua configuração funcional, podendo assim desenvolver novas proteínas para combater diversas doenças. Como os demais projetos da família, os voluntários tinham que executar o instalador do projeto utilizando o BOINC e este só iria entrar em funcionamento quando o computador estivesse ocioso, em modo de protetor de tela. Porém, diversos emails foram enviados ao projeto de voluntários que queriam contribuir mais, dizendo ser possível obter melhores resultados se eles pudessem interagir com o modelo de proteína que estava aparecendo ali no protetor de tela. 

Com isto em mente, David Baker desenvolveu um novo projeto de pensamento voluntário com características de um jogo através da internet, onde os voluntários são os jogadores e precisão achar as melhores soluções para os desafios, utilizando o enovelamento de proteínas \cite{Hand2010}. \textit{Foldit}, lançado em 2008, provou que os voluntários conseguem realizar um melhor trabalho do que um computador. Este é um dos primeiros trabalhos que envolve tanto computação voluntária quanto o pensamento voluntário \cite{Cooper2010}.

Um dos resultados mais significativos, foi alcançado pelos jogadores do projeto \textit{Foldit} em 2011, onde os voluntários resolveram um problema proposto pelos pesquisadores ``jogando'' em apenas 3 semanas. Os cientistas lançaram o desafio a partir do instante em que os métodos automáticos começaram a não retornar bons resultados, ao analisar os resultados dos jogadores, observaram que estes eram suficientemente bons para encontrar uma rápida solução \cite{Khatib2011}.

\citeonline{mcgonigal2011reality} sugere que os problemas atuais poderiam ser solucionados efetivamente de outra forma, através dos jogos. Concientizando pessoas dos problemas reais e inserindo os diversos problemas como contexto dos jogos, os jogadores iriam buscar soluções para estes desafios. Diversos pesquisadores sugerem que construir projetos de ciência com a temática na forma de jogos poderiam atrair ainda mais os voluntários e resolver ainda mais rápido os desafios empregados \cite{Silvertown2009,Hand2010,Khatib2011,Anderson1999,Pereira:2013:NoInUs,Cooper2010,Mansell2012}.

\section{Sensoriamento Voluntário}
\label{ch:sensoriamento_voluntario}

As duas formas de ciência cidadã discutidas anteriormente tem suas vantagens conforme a necessidade do método de pesquisa científica que irá ser executada. Computação voluntária tem maior vantagem para as atividades científicas que requerem grande poder computacional, avaliando grandes quantidades de dados, o que levariam horas para uma pessoa realizar. Já o pensamento voluntário, mostra-se mais eficaz em atividades que requerem o poder cognitivo dos voluntários, como detecções de padrões utilizando inspeção visual.

Algumas vezes, os dados disponíveis para projetos científicos não são suficientes e a coleta de outros tipos de medidas se faz necessária. Adquirir novas fontes de dados não é um simples trabalho, necessita-se de equipes capazes de efetuar as coletas científicas conforme padrões exigidos e ferramentas adequadas para tal.
A realização desta tarefa, porém, se feita apenas pelos cientistas envolvidos diretamente com o projeto, pode se tornar custosa e demorada. Portanto, uma alternativa viável é a utilização de sensoriamento voluntário onde voluntários contribuem com dados, sejam anotações de observações, captação de imagem ou sons de um ambiente. A tecnologia atual permite soluções de menor custo para coletar diversos tipos de dados para serem utilizados em projetos científicos.

O sensoriamento voluntário é uma junção de Informação Geográfica Voluntariada (IGV), termo de \citeonline{Goodchild2007} para descrever as tarefas realizadas por voluntários ao fornecer dados complementares a determinadas localizações geográficas com a finalidade de enriqucer a base de dados, com sensoriamento móvel \cite{Lane2010}, onde pesquisas são conduzidas através de aparelhos móveis dos voluntários utilizando os sensores disponíveis neste. 

\subsection{Informação Geográfica Voluntariada}

\citeonline{Goodchild2007} categoriza de \textbf{informação geográfica voluntariada} o fenômeno que vem atraindo cidadãos de toda parte, a criação de informações geográficas. Tarefa que antigamente era de uso exclusivo das agências oficiais responsáveis por realizar cartografias dos países, porém com o avanço da tecnologia, qualquer pessoa pode ter acesso a ferramentas de edição de mapa online e colaborar com alguma informação geográfica. Seja esta específica sobre um determinado prédio, dado sua latitude e longitude, como também por vastos terrenos, ao descrever uma cidade. Este recente paradigma representa uma dramática inovação e certamente terá grandes impactos aos sistemas de informação geográfica.

Este conceito de criação de dados geográficos por voluntários vem sendo amplamente estudado por diferentes frentes. Para a indústria, o desenvolvimento de plataformas baseado em web onde os usuários possam enviar seus dados. Para o governo, o conceito é estudado para possíveis aplicação em sistemas de alerta a surtos de doenças e monitoramento constante para verificar os impactos ambientais locais causados por mudanças climáticas globais. Para pesquisadores acadêmicos em como adaptar ambientes de sistemas de informação geográficos para utilizar, armazenar e analisar os dados coletados por voluntários \cite{elwood2008volunteered}.

Um marcante projeto de informação geográfica voluntariada, \textit{Wikimapia}, é referência nesta categoria, onde voluntários podem contribuir com novas informações geográficas simplesmente escolhendo um local (através de uma coordenada geográfica) e complementando a informação local \cite{Wikimapia:online}. Possui um objetivo ambicioso de descrever todo o globo terrestre com o máximo de informções geográficas utéis reunidas através do uso de voluntários, organizá-las e disponibilizá-las para diversos outros usos públicos das informação. Através de uma interface simples, figura \ref{fig:wikimapia}, para que os voluntários que não possuam experiências com edição de mapas possam também, de forma rápida e intuitiva, colaborar com o projeto. Foi lançado em maio de 2006 como uma ferramenta similar a wikipedia, onde todos podem editar seu conteúdo, e em pouco tempo diversos voltuntários já haviam se cadastrado, com menos de 3 meses o projeto possuia 1 milhão de novos registros geográficos criados apenas por voluntários. Em julho de 2012 o projeto já atingia a marca de 19 milhões de registros geográficos criados \cite{Wikimapia:history}.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figuras/wikimapia.png}
    \caption{Modo de inserção de dados do portal wikimapia.}
    %\FONTE{\citeonline{NASA}}
    \label{fig:wikimapia}
\end{figure}

Outro projeto que merece destaque nesta categoria é o renomado \textit{OpenStreetMaps}. Muito parecido com a ferramenta de mapas do Google, mas de forma livre, o OSM possui diferentes características e funcionalidades. Lançado em julho de 2004 e deste então vem atraindo novos voluntários a cada dia, tendo um crescimento constante (ver figura \ref{fig:osm_table}). Construído para que voluntários mantenham sempre os dados geográficos atualizados, assim como o wikimapia, porém o OSM conta diversas funcionalidades para integração dos seus dados a projetos de terceiros, utilizando-se de protocolos abertos e com muitas opções para exportar os dados. 

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figuras/osm_table.PNG}
    \caption{Gráfico do crescimento mensal de usuários registrados e contribuições realizadas ao projeto \textit{OpenStreetMap}.}
    \FONTE{\citeonline{haklay2008openstreetmap}}
    \label{fig:osm_table}
\end{figure}

\subsubsection{Sistemas de Alertas}

Estudos sugerem que este novo conceito de explorar e criar informações geográficas podem levar a um novo paradigma de criação de sistemas de alertas, considerando que cada pessoa como um sensor, há cerca de 6 bilhões de sensores no globo \cite{elwood2008volunteered,Goodchild2007,Gouveia2004,Gouveia2008}. Geralmente, no segundo momento após um desastre como os ocasionados por furacões e tsunamis, é difícil de se ter informações sobre os locais que foram afetados por inúmeras razões, seja por falta de eletricidade, um bom campo de visão para se obter imagens ou equipamentos de comunicação. Porém a população das áreas afetadas conhecem suficientemente bem o local e poderia reportar ou auxiliar atividades como de resgate através de dispositivos móveis utilizando mensagens, imagens e voz. \citeonline{Goodchild2007} reportar que um sistema deste nível há de existir nos próximos anos. Em seu trabalho \citeonline{Schade2011} conclui que dados geográficos obtidos por voluntários podem ser complementares aos dados de sensoriamento remoto.

\subsection{Sensoriamento Móvel}
A era pós-PC, mencionado pela primeira vez por \citeonline{DavidClark2013:bio}, em que estimava que os computadores deixariam de ser o principal dispositivo eletrônico está se tornando realidade. Os computadores pessoais estão sendo descentralizados, como a décadas muitos já previam. Sua utilidade está mais fardada a um \textit{hub} tecnológico, servindo de meio de comunicação com outros dispositivos móveis como smartphones e tablets. 

No início dos anos 90, os celulares eram realidades para pouco, mas diversos fatores alteraram a rota deste para a sua popularização. O avanço da tecnologia permitiu reduzir o tamanho dos componentes eletrônicos e sensores físicos digitais, também a quantidade de energia requerida por esses. 

Diversos tipos de sensores estão cada vez mais presentes em celulares, tornando dispositivos móveis em unidades de coleta de informação de grande precisão. Câmeras e sensores de localização já são frequentes na maioria dos celulares, estes permitem obter a sua localização em qualquer parte do globo terrestre através de \textit{GPS}\footnote{\textbf{G}lobal \textbf{P}ositioning \textbf{S}ystem é um sistema de navegação baseado em uma constelação de 24 satélites.}, sendo alguns modernos integrado com \textit{GLONASS}\footnote{\textbf{GLO}bal \textbf{NA}vigatsionnaya \textbf{S}putnikovaya \textbf{S}istema, um sistema de navegação russo, constituído por uma constelação de 21 satélites}. Há também dispositivos que apresentam sensores de proximidade, giroscópio, magenetômetro, acelerômetro, barômetro e de luz ambiente. Mas sempre há um sensor presente nos celulares, o microfone que em conjunto com os demais sensores supracitados torna-se uma poderosa ferramenta de monitoramento ambiental.

Em recentes relatórios, \citeonline{Gartner2014} aponta que em 2015 os dispositivos móveis (tablets, celulares e smartphones) irão ultrapassar os computadores pessoais (computadores de mesa e portáteis), em quantidade, conforme figura \ref{fig:gartner}.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figuras/gartner2014.png}
    \caption{Relatório Gartner julho/2014}
    \FONTE{\citeonline{Gartner2014}}
    \label{fig:gartner}
\end{figure}

Com esta visão, novos projetos tem surgido com a intenção de utilizar os sensores presentes nos dispositivos móveis como fonte de dados científicos, coletando constantemente informações do dia a dia de quem os utilizam \cite{Lane2010,Burke2006}. 



Por anos a comunidade acadêmica e industrial vem debatendo o uso de dispositivos móveis em pesquisas de sensoriamento, porém sem grandes avanços até datas recentes. \citeonline{Lane2010} atribui esta mudanças aos seguintes fatores:

\begin{enumerate}
    \item Sensores embarcados - utilizados primeiramente como forma de melhorar a experiência de uso para os usuários, como acelerômetro, encontraram novas formas de uso e chamaram a ateção de pesquisadores. Diversos sensores novos estão revolucionando as pesquisas, como GPS e barômetro.
    \item Programáveis - Há uma coleção infinita de documentação na internet de como programar para dispositivos móveis de terceiros. As grandes plataformas de dispositivo móveis, como Apple, Google, e Windows Phone possuem documentações detalhadas, permitindo qualquer pessoa com um pouco de conhecimento de programação aprender a linguagem e desenvolver aplicativos.
    \item Lojas de aplicativo - Os desenvolvedores de aplicativos utilizam o serviço de loja de aplicativo do fabricante correspondente para publicar sua nova criação. Permitindo alcançar diferentes tipos de usuários em toda a parte.
    \item Computação na nuvem - Utilizando-se de computação na nuvem, os dispositivos móveis podem armazenar dados e até efetuar cálculos através de servidores na internet, sem a necessidade de utilizar estas funcionalidades apenas local, proporcionando um grande crescimento de uso e descentralização de dados.
\end{enumerate}


\chapter{ForestWatchers}
\label{ch:forestwatchers}

O projeto ForestWatchers (\url{http://www.forestwatchers.net}) propõe o desenvolvimento e o lançamento de uma iniciativa de ciência cidadã com o objetivo de envolver e integrar cidadãos ao redor do planeta na tarefa de monitorar o desmatamento das florestas tropicais \cite{ForestWatchersDesc}. Estes cidadãos poderão de suas casas, por meio de uma interface \textit{Web}, inspecionar imagens recentes de satélite de áreas de florestas. Estas podem ser de uma reserva indígena na Amazônia, uma floresta nacional em Bornéu ou um parque em Queensland. As imagens são então classificadas em áreas de floresta ou não-floresta, por meio de um algoritmo de classificação supervisionado pelos voluntários na \textit{Web}. Conforme mencionado por \citeonline{Ipeirotis2010}, erros e até mesmo fraude podem ser automaticamente tratados pela redundância do sistema. Para isso, é necessário atrair e manter um grande número de voluntários \cite{Soares:2011:EmCiSc}. Estima-se que cem mil voluntários analisando uma área de 100.000 hectares cada, com um fator de redundância de 20, podem examinar uma área de 500 milhões de hectares, cerca de 40\% a 50\% da área estimada das florestas tropicais do mundo \cite{ForestWatchersDesc}.

O projeto conta com desenvolvedores do Laboratório Associado de Computação e Matemática Aplicada (LAC) do INPE, do \textit{Citizen Cyberscience Centre} (CCC), e do Departamento de Ciência e Tecnologia (DCT) da Universidade Federal de São Paulo (UNIFESP), com apoio do \textit{Open Society Foundations} (OSF), \textit{United Nations Institute for Training and Research} (UNITAR), e \textit{UNITAR's Operational Satellite Application Programme} (UNOSAT).

A seguir, será discutida a metodologia empregada no projeto.

\section{Metodologia}
\label{ch:metodologia}

A metodologia usada neste projeto é inspirada no bem-sucedido programa de detecção de desflorestamento DETER do INPE. Assim, como no sistema DETER, o projeto ForestWatchers também utiliza imagens do sensor MODIS, com resolução de $250$ metros (porém qualquer outro sensor de satélite que forneça suas imagens gratuitamente pode ser utilizado). Para que essas imagens possam ser exibidas para os voluntários é necessário que um pré-processamento seja feito. 

Um diagrama ilustrativo da metodologia utilizada pelo projeto ForestWatchers pode ser visto na Figura \ref{fig:estrutura_atual}.
\begin{figure}[htb]
\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figuras/arquitetura_atual.png}
\caption{A metodologia utilizada pelo projeto ForestWatchers.}
\label{fig:estrutura_atual}
\FONTE{\citeonline{ForestWatchersDesc}}
\end{figure}

Primeiramente é necessário adquirir as imagens da NASA referentes à área de interesse do projeto. Para esse processo, ferramentas como FTP\footnote{\textit{File Transfer Protocol (FTP)} é um protocolo para transferência de arquivo utilizado na Internet para efetuar \textit{downloads} e \textit{uploads} de arquivos.}e WGET\footnote{WGET é um programa livre para efetuar \textit{download} de conteúdos na Internet.} são utilizadas para realizar os downloads necessários. A próxima etapa, envolve recortar as imagens que não são pertinentes à área de interesse, descartando-as e consolidando as imagens restantes num único arquivo GeoTIFF de 16 bits. Essa etapa pode ser executada rapidamente com o auxílio da ferramenta MODIS Reprojection Tool (MRT) \cite{MRToolManual2010}, um software gratuito disponibilizado pela NASA.

As imagens de 16 bits são convertidas para 8 bits por meio de um \textit{script} em Python\footnote{Python é uma linguagem de programação aberta.}. Logo após, uma única imagem é consolidada utilizando-se três bandas (infravermelho médio, vermelho, infravermelho próximo, equivalentes a vermelho, verde e azul) da imagem de 8 bits. Assim, essa imagem pode ser enviada para um servidor gerenciador de arquivos de mapa. Nesse projeto utiliza-se o MapServer (\url{http://www.mapserver.org}), responsável por tratar as requisições de inserção e seleção das imagens georreferenciadas, e de retornar apenas parte da imagem desejada na forma de \textit{tiles}. Todos os arquivos relacionados à imagem têm suas informações extraídas no formato GeoJSON\footnote{\textit{Geographic JavaScript Object Notation} é um formato para codificar variados tipos de estruturas geográficas.}, para facilitar a comunicação entre os outros módulos. O algoritmo de classificação (ainda em desenvolvimento) faz a segmentação das imagens, classificando-as como  áreas de floresta e de não-floresta. Existindo a necessidade de supervisão das imagens, serão criadas tarefas para os usuários poderem classificá-las visualmente.

O \citeonline{PyBossa2013} é o sistema responsável por gerenciar a criação e distribuição das tarefas automaticamente, conforme necessário. Esse é um sistema livre que permite um usuário criar e gerenciar projetos que requeiram cognição humana, tais como classificação de imagem, transcrição e geo-codificação. Esse sistema é baseado no \citeonline{Boinc2008}, plataforma online desenvolvida para facilitar a criação e a operação de projetos baseados em ciência cidadã. Essa nova implementação traz maiores benefícios em relação ao sistema original, Bossa, por ser desenvolvida em Python e possuir uma API\footnote{\textit{Application Programming Interface} (API) é um protocolo com o objetivo de servir como interface para os componentes de softwares, permitindo comunicarem entre si.} RESTful \cite{Richardson2008}. 

Com as tarefas criadas, os voluntários podem classificar as imagens de forma ordenada. O projeto, com o uso do sistema de redundância que envia a mesma tarefa para diferentes voluntários, garante um aumento na confiabilidade dos resultados \cite{Ipeirotis2010}.

\chapter{Metodologia}
\label{ch:metodologia}

O conceito de um módulo de sensoriamento voluntário consiste básicamente de \textbf{(a)} um dispositivo capaz de coletar dados, \textbf{(b)} estrutura de recebimento e armazenamento, e \textbf{(c)} um sistema de visualização dos dados obtidos \cite{VolunteerSensing2011,Gouveia2008}. 

Para a validação deste conceito o seguinte módulo foi construído em duas etapas. Um aplicativo híbrido, utilizado pelos voluntários para enviarem os dados coletados a partir de um dispositivo móvel. E uma infraestrutura tecnológica, divida em: uma camada de recebimento e armazenamento, processamento e visualização dos dados.

Este capítudo descreve a metodologia utilizada em cada etapa da construção do módulo, por fim, detalha o experimento de coleta de dados utilizado por este módulo.

\section{Aplicativos} % (fold)
\label{sub:aplicativos}

% Até o momento, a aplicação móvel é a única forma que os voluntários têm para submeter dados de coleta ao projeto.
Supondo que um vetor de coleta de dados de difícil acesso, com alta complexibilidade e desenvolvido com o único propósito de coletar dados, construídos sobre demanda, sejam fatores inibidores, restringindo significantemente o número de possíveis voluntários comitidos com o projeto \cite{Lane2010}. Optou-se por utilizar uma aplicação desenvolvida para dispositivos móveis (smartphones e tablet). Hoje, a grande maioria possui um dispositivo móvel com capacidade de conectar-se a internet, tirar fotos, captar áudio e gravar vídeos. Com a popularização dos sensores embargados em dispositivos móveis e as expectativas de crescimento deste mercado \cite{Lane2010,Gartner2014}, utilizá-los como ferramenta para projetos de ciência cidadã parecem bastante sugestivas.

Foram criados quatro aplicativos como protótipos para testar suas funcionalidades verificarem a sua significância em relação as necessidades do projeto: (i) dois destes aplicativos utilizando-se sistemas prontos ou de fácil uso para a criação da ferramenta de coleta de dados. Há ferramentas disponíveis gratuitamente para auxiliar a construção de aplicativos para dispositivos móveis. Estes, em grande parte, seguem o princípio aberto-fechados \cite{meyer1988:open_closed}, onde uma pessoa com conhecimento pode estender as funcionalidades principais, mas não modificá-las diretamente; (ii) um utilizando bibliotecas nativas, disponibilizadas pelos fabricantes de dispositivos móveis para criar novos aplicativos, como estes que são fácilmente encontrados nas lojas online de aplicativos; e por fim, (iii) um utilizando uma abordagem de desenvolvimento de aplicativos híbrido, onde há uma biblioteca em comum entre os demais dispositivos existentes e necessitando de apenas uma linguagem de programação.

A metodologia para o desenvolvimento dos protótipos (i), (ii) e (iii) são descritos nas seções \ref{ssub:aplicativo_com_sistemas_prontos}, \ref{ssub:aplicativo_com_biblioteca_nativa} e \ref{ssub:aplicativo_com_biblioteca_hibrida}, respectivamente.

\subsection{Aplicativo com Sistemas Prontos} % (fold)
\label{ssub:aplicativo_com_sistemas_prontos}

Existem alguns aplicativos que permitem criar ferramentas de coleta de dados com sensores utilizando formulários feitos através de interfaces gráficas e inserido no aplicativo. Estes sistemas prontos são indicados para efetuar a criação aplicativos voltado para pesquisas ou coleta de dados de uma forma rápida, uma vez que estas possuem toda uma infraestrutura para armazenamento de dados e interface gráfica para a construção dos formulários.

EpiCollect é um destes sistemas e foi utilizado para construir o primeiro protótipo do projeto.
Foi desenvolvido um formulário baseado nos principais requisitos do projeto no qual visa captar áudio, vídeo e imagem juntamente com a coordenada geográfica atual do voluntário, conforme este observa um fenômeno.

Este sistema é de muito fácil uso, bastando ter acesso a internet para cadastrar-se e criar o formulário. 

\subsection{Aplicativo com Biblioteca Nativa} % (fold)
\label{ssub:aplicativo_com_biblioteca_nativa}

\subsection{Aplicativo com Biblioteca Híbrida} % (fold)
\label{ssub:aplicativo_com_biblioteca_hibrida}

\section{Infraestrutura Tecnológica} % (fold)
\label{sub:infraestrutura_tecnologica}

\subsection{Armazenamento} % (fold)
\label{sub:armazenamento}

\subsection{Servidor para Internet} % (fold)
\label{sub:servidor_web}

\subsubsection{Back-End} % (fold)
\label{ssub:back_end}

\subsubsection{Front-End} % (fold)
\label{ssub:front_end}


\section{Coleta de Dados} % (fold)
\label{sub:coleta_de_dados}






\chapter{Resultados e Discussões}
\label{ch:resultados}

\section{Conclusões e Trabalhos Futuros}
\label{ch:conclusoes}